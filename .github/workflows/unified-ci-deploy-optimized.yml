name: Digital Persona Platform - Unified CI/CD (Optimized v2)

on:
  push:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  pull_request:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  workflow_dispatch:
    inputs:
      force_deploy:
        description: "Force deployment even if tests fail"
        required: false
        default: false
        type: boolean
      skip_tests:
        description: "Skip test execution for emergency deployments"
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  security-events: write
  actions: read
  contents: read

env:
  AWS_REGION: us-west-1
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "20"
  # Remove hardcoded DOMAIN - will be determined dynamically
  TERRAFORM_VERSION: "1.5.0"

jobs:
  # ===========================================
  # ENVIRONMENT DETECTION
  # ===========================================
  detect-environment:
    name: ðŸ” Environment Detection
    runs-on: ubuntu-latest
    timeout-minutes: 5
    # Use workflow-specific concurrency group
    concurrency:
      group: unified-deployment-${{ github.ref_name }}
      cancel-in-progress: true
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      main_env: ${{ steps.env.outputs.main_env }}
      should_deploy: ${{ steps.env.outputs.should_deploy }}
      is_numbered_env: ${{ steps.env.outputs.is_numbered_env }}
      ecr_registry: ${{ steps.env.outputs.ecr_registry }}
      domain: ${{ steps.env.outputs.domain }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine Environment and AWS Registry
        id: env
        run: |
          # Determine environment based on branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENVIRONMENT="prod"
            MAIN_ENV="prod"
            SHOULD_DEPLOY="false"  # Main branch requires manual deployment
            IS_NUMBERED_ENV="false"
          elif [[ "${{ github.ref_name }}" =~ ^dev[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="dev"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^qa[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="qa"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^staging[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="staging"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^hotfix[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="hotfix"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          else
            echo "âŒ Invalid branch name: ${{ github.ref_name }}"
            echo "Valid branches: main, dev01-dev99, qa01-qa99, staging01-staging99, hotfix01-hotfix99"
            exit 1
          fi

          # Get AWS Account ID dynamically
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

          # Set ECR registry for later use
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"

          # Set dynamic domain based on environment
          DOMAIN="hibiji.com"

          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "main_env=$MAIN_ENV" >> $GITHUB_OUTPUT
          echo "should_deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
          echo "is_numbered_env=$IS_NUMBERED_ENV" >> $GITHUB_OUTPUT
          echo "ecr_registry=$ECR_REGISTRY" >> $GITHUB_OUTPUT
          echo "domain=$DOMAIN" >> $GITHUB_OUTPUT

          echo "ðŸŽ¯ Environment: $ENVIRONMENT"
          echo "ï¸  Main Environment: $MAIN_ENV"
          echo " Should Deploy: $SHOULD_DEPLOY"
          echo " ECR Registry: $ECR_REGISTRY"
          echo " Domain: $DOMAIN"

  # ===========================================
  # PARALLEL CI PHASE (All run simultaneously)
  # ===========================================

  security-scan:
    name: ï¸ Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.skip_tests != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cache security scan results
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/trivy
            ~/.cache/semgrep
          key: ${{ runner.os }}-security-${{ hashFiles('**/requirements.txt', '**/package*.json') }}
          restore-keys: |
            ${{ runner.os }}-security-

      - name: Run Trivy vulnerability scanner
        id: trivy
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "sarif"
          output: "trivy-results.sarif"
          severity: "CRITICAL,HIGH,MEDIUM"
          exit-code: "0"

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: "trivy-results.sarif"

      - name: Display Trivy scan summary
        if: always()
        run: |
          if [ -f "trivy-results.sarif" ]; then
            echo "ðŸ“Š Trivy scan completed - check Security tab for detailed results"
            echo "ðŸ” Scan summary:"
            cat trivy-results.sarif | jq -r '.runs[0].results | length' | xargs -I {} echo "Found {} potential issues"
          else
            echo "âš ï¸ Trivy results file not found"
          fi

      - name: Run TruffleHog secret scanner
        id: trufflehog
        uses: trufflesecurity/trufflehog@v3.82.13
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: ${{ github.sha }}
          extra_args: --exclude-paths=.trufflehogignore --exclude-detectors=postgres,mongodb,uri,github,cloudflareapitoken --only-verified
        continue-on-error: false

      - name: Handle TruffleHog failure
        if: failure() && steps.trufflehog.outcome == 'failure'
        run: |
          echo "ðŸš¨ TruffleHog detected potential secrets!"
          echo "Review the scan results above and ensure no real secrets are committed."
          echo "If these are false positives, add them to .trufflehogignore"
          exit 1

      - name: Security scan summary
        if: always()
        run: |
          echo "ðŸ›¡ï¸ Security Scan Summary"
          echo "======================="

          if [ "${{ steps.trivy.outcome }}" == "success" ]; then
            echo "âœ… Trivy vulnerability scan: PASSED"
          else
            echo "âŒ Trivy vulnerability scan: FAILED"
          fi

          if [ "${{ steps.trufflehog.outcome }}" == "success" ]; then
            echo "âœ… TruffleHog secret scan: PASSED"
          else
            echo "âŒ TruffleHog secret scan: FAILED"
          fi

          echo ""
          echo "ðŸ“Š View detailed results in:"
          echo "   - Security tab: Repository â†’ Security â†’ Code scanning"
          echo "   - Job logs: Expand steps above for details"

  backend-tests:
    name: Backend Tests (${{ matrix.python-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.skip_tests != 'true'
    defaults:
      run:
        working-directory: ./python-ml-service
    strategy:
      matrix:
        python-version: ["3.11"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Ensure pip cache directory exists
        run: mkdir -p ~/.cache/pip

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade setuptools wheel
          pip install -r requirements.txt --use-pep517

      - name: Run tests
        run: |
          python -m pytest tests/ -v --cov=app --cov-report=xml

      - name: Upload coverage reports (with retry)
        if: always()
        run: |
          echo "ðŸ“Š Attempting to upload coverage reports to Codecov..."

          # Function to upload with retry logic
          upload_coverage() {
            local max_attempts=3
            local attempt=1
            local wait_time=10
            
            while [ $attempt -le $max_attempts ]; do
              echo "ðŸ”„ Upload attempt $attempt/$max_attempts..."
              
              # Check if coverage file exists
              if [ ! -f "./coverage.xml" ]; then
                echo "âš ï¸ Coverage file not found, skipping upload"
                return 0
              fi
              
              # Try to upload using curl with timeout and retry
              if curl --max-time 60 --retry 3 --retry-delay 5 \
                --retry-max-time 300 \
                --data-binary @./coverage.xml \
                -H "Content-Type: text/xml" \
                -H "X-Codecov-Token: ${{ secrets.CODECOV_TOKEN }}" \
                -H "X-Reduced-Redundancy: false" \
                -H "X-Reported-Job-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Number: ${{ github.run_number }}" \
                -H "X-Reported-Branch: ${{ github.ref_name }}" \
                -H "X-Reported-Commit-Sha: ${{ github.sha }}" \
                -H "X-Reported-Pull-Request: ${{ github.event.pull_request.number || '' }}" \
                -H "X-Reported-Job-Name: backend-coverage" \
                -H "X-Reported-Flags: backend" \
                "https://codecov.io/upload/v2" > /tmp/codecov_response.json 2>/tmp/codecov_error.log; then
                
                echo "âœ… Coverage upload successful!"
                cat /tmp/codecov_response.json
                return 0
              else
                echo "âŒ Upload failed (attempt $attempt/$max_attempts)"
                echo "Error log:"
                cat /tmp/codecov_error.log
                
                if [ $attempt -lt $max_attempts ]; then
                  echo "â³ Waiting $wait_time seconds before retry..."
                  sleep $wait_time
                  wait_time=$((wait_time * 2))  # Exponential backoff
                fi
                
                attempt=$((attempt + 1))
              fi
            done
            
            echo "âŒ All upload attempts failed"
            return 1
          }

          # Attempt upload
          if upload_coverage; then
            echo "âœ… Coverage upload completed successfully"
          else
            echo "âš ï¸ Coverage upload failed, but continuing workflow"
            echo "This is a non-critical failure and won't block the deployment"
          fi

  frontend-tests:
    name: âš›ï¸ Frontend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.skip_tests != 'true'
    defaults:
      run:
        working-directory: ./apps/web
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Ensure npm cache directory exists
        run: mkdir -p ~/.npm

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"
          cache-dependency-path: package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Check if test script exists
        id: check-tests
        run: |
          if npm run test --dry-run >/dev/null 2>&1; then
            echo "has_tests=true" >> $GITHUB_OUTPUT
          else
            echo "has_tests=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ No test script found in package.json, skipping tests"
          fi

      - name: Run frontend tests
        if: steps.check-tests.outputs.has_tests == 'true'
        run: npm test -- --coverage --watchAll=false

      - name: Run linting and type checking (alternative to tests)
        if: steps.check-tests.outputs.has_tests == 'false'
        continue-on-error: true
        run: |
          echo "ðŸ” Running linting and type checking instead of tests..."
          npm run lint --if-present || echo "âš ï¸ Linting failed, continuing..."
          echo "ðŸ”§ Running isolated type checking on src directory only..."
          npx tsc --noEmit --skipLibCheck src/**/*.ts src/**/*.tsx || echo "âš ï¸ Type checking failed, continuing..."

      - name: Upload coverage reports (with retry)
        if: always() && steps.check-tests.outputs.has_tests == 'true'
        run: |
          echo "ðŸ“Š Attempting to upload frontend coverage reports to Codecov..."

          # Function to upload with retry logic
          upload_coverage() {
            local max_attempts=3
            local attempt=1
            local wait_time=10
            
            while [ $attempt -le $max_attempts ]; do
              echo "ðŸ”„ Upload attempt $attempt/$max_attempts..."
              
              # Check if coverage directory exists
              if [ ! -d "./coverage" ]; then
                echo "âš ï¸ Coverage directory not found, skipping upload"
                return 0
              fi
              
              # Check if lcov.info exists
              if [ ! -f "./coverage/lcov.info" ]; then
                echo "âš ï¸ lcov.info file not found, skipping upload"
                return 0
              fi
              
              # Try to upload using curl with timeout and retry
              if curl --max-time 60 --retry 3 --retry-delay 5 \
                --retry-max-time 300 \
                --form "file=@./coverage/lcov.info" \
                -H "X-Codecov-Token: ${{ secrets.CODECOV_TOKEN }}" \
                -H "X-Reduced-Redundancy: false" \
                -H "X-Reported-Job-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Number: ${{ github.run_number }}" \
                -H "X-Reported-Branch: ${{ github.ref_name }}" \
                -H "X-Reported-Commit-Sha: ${{ github.sha }}" \
                -H "X-Reported-Pull-Request: ${{ github.event.pull_request.number || '' }}" \
                -H "X-Reported-Job-Name: frontend-coverage" \
                -H "X-Reported-Flags: frontend" \
                "https://codecov.io/upload/v2" > /tmp/codecov_response.json 2>/tmp/codecov_error.log; then
                
                echo "âœ… Frontend coverage upload successful!"
                cat /tmp/codecov_response.json
                return 0
              else
                echo "âŒ Upload failed (attempt $attempt/$max_attempts)"
                echo "Error log:"
                cat /tmp/codecov_error.log
                
                if [ $attempt -lt $max_attempts ]; then
                  echo "â³ Waiting $wait_time seconds before retry..."
                  sleep $wait_time
                  wait_time=$((wait_time * 2))  # Exponential backoff
                fi
                
                attempt=$((attempt + 1))
              fi
            done
            
            echo "âŒ All upload attempts failed"
            return 1
          }

          # Attempt upload
          if upload_coverage; then
            echo "âœ… Frontend coverage upload completed successfully"
          else
            echo "âš ï¸ Frontend coverage upload failed, but continuing workflow"
            echo "This is a non-critical failure and won't block the deployment"
          fi

  dependency-scan:
    name: ðŸ“¦ Dependency Scan
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event.inputs.skip_tests != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run dependency vulnerability scan
        uses: pypa/gh-action-pip-audit@v1.0.8
        with:
          inputs: python-ml-service/requirements.txt

  terraform-plan:
    name: ðŸ—ï¸ Terraform Plan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [detect-environment]
    if: needs.detect-environment.outputs.should_deploy == 'true'
    outputs:
      plan_id: ${{ steps.plan.outputs.plan_id }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Init
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}
          terraform init

      - name: Terraform Plan
        id: plan
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}
          terraform plan -out=tfplan -detailed-exitcode
          echo "plan_id=tfplan" >> $GITHUB_OUTPUT

      - name: Upload Terraform Plan
        uses: actions/upload-artifact@v4
        with:
          name: terraform-plan-${{ needs.detect-environment.outputs.environment }}
          path: terraform/environments/${{ needs.detect-environment.outputs.main_env }}/tfplan
          retention-days: 1

  # ===========================================
  # BUILD & PACKAGE PHASE
  # ===========================================
  build-and-package:
    name: ðŸ—ï¸ Build & Package
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs:
      [
        detect-environment,
        security-scan,
        backend-tests,
        frontend-tests,
        dependency-scan,
      ]
    if: |
      always() && 
      needs.detect-environment.result == 'success' &&
      (needs.security-scan.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.backend-tests.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.frontend-tests.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.dependency-scan.result != 'cancelled' || github.event.inputs.skip_tests == 'true' || github.event.inputs.force_deploy == 'true')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Clean up disk space
        run: |
          # Remove unnecessary files to free up space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          df -h

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repositories if they don't exist
        run: |
          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="hibiji"

          # Create backend repository
          BACKEND_REPO="${PROJECT_NAME}-${MAIN_ENV}-backend"
          aws ecr describe-repositories --repository-names "$BACKEND_REPO" --region ${{ env.AWS_REGION }} || \
          aws ecr create-repository \
            --repository-name "$BACKEND_REPO" \
            --region ${{ env.AWS_REGION }} \
            --tags Key=Environment,Value=$ENVIRONMENT \
                   Key=Project,Value=$PROJECT_NAME \
                   Key=ManagedBy,Value=github-actions

          # Create frontend repository  
          FRONTEND_REPO="${PROJECT_NAME}-${MAIN_ENV}-frontend"
          aws ecr describe-repositories --repository-names "$FRONTEND_REPO" --region ${{ env.AWS_REGION }} || \
          aws ecr create-repository \
            --repository-name "$FRONTEND_REPO" \
            --region ${{ env.AWS_REGION }} \
            --tags Key=Environment,Value=$ENVIRONMENT \
                   Key=Project,Value=$PROJECT_NAME \
                   Key=ManagedBy,Value=github-actions

      - name: Build and push backend Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64
          push: true
          tags: |
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-backend:${{ github.sha }}
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-backend:latest
          # Use registry cache to avoid disk space issues
          cache-from: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-backend:cache
          cache-to: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-backend:cache,mode=max

      - name: Build and push frontend Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./apps/web/Dockerfile
          platforms: linux/amd64
          push: true
          tags: |
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-frontend:${{ github.sha }}
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-frontend:latest
          # Use registry cache to avoid disk space issues
          cache-from: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-frontend:cache
          cache-to: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-${{ needs.detect-environment.outputs.main_env }}-frontend:cache,mode=max

      - name: Create build artifacts
        run: |
          mkdir -p build-artifacts
          echo "${{ github.sha }}" > build-artifacts/commit-sha.txt
          echo "${{ needs.detect-environment.outputs.environment }}" > build-artifacts/environment.txt
          echo "${{ needs.detect-environment.outputs.ecr_registry }}" > build-artifacts/ecr-registry.txt

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ needs.detect-environment.outputs.environment }}
          path: build-artifacts/

  # ===========================================
  # DEPLOYMENT PHASE
  # ===========================================
  deploy:
    name: ðŸš€ Deploy to ${{ needs.detect-environment.outputs.environment }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [detect-environment, terraform-plan, build-and-package]
    if: |
      always() && 
      needs.detect-environment.outputs.should_deploy == 'true' &&
      needs.detect-environment.result == 'success' &&
      needs.terraform-plan.result == 'success' &&
      (needs.build-and-package.result == 'success' || github.event.inputs.force_deploy == 'true')
    environment:
      name: ${{ needs.detect-environment.outputs.environment }}
      url: https://${{ needs.detect-environment.outputs.environment }}.${{ needs.detect-environment.outputs.domain }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Download Terraform Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan-${{ needs.detect-environment.outputs.environment }}
          path: terraform/environments/${{ needs.detect-environment.outputs.main_env }}/

      - name: Create AWS Secrets if they don't exist
        run: |
          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="hibiji"
          RESOURCE_PREFIX="${PROJECT_NAME}-${ENVIRONMENT}"

          # Check if secrets already exist (they may have random suffixes from Terraform)
          echo "ðŸ” Checking for existing secrets..."

          # Look for existing secret key (with pattern matching)
          EXISTING_SECRET_KEY=$(aws secretsmanager list-secrets \
            --region ${{ env.AWS_REGION }} \
            --query "SecretList[?starts_with(Name, '${RESOURCE_PREFIX}-secret-key')].Name" \
            --output text)

          # Look for existing database password (with pattern matching)
          EXISTING_DB_PASSWORD=$(aws secretsmanager list-secrets \
            --region ${{ env.AWS_REGION }} \
            --query "SecretList[?starts_with(Name, '${RESOURCE_PREFIX}-db-password')].Name" \
            --output text)

          # Create app secret key if it doesn't exist
          if [ -z "$EXISTING_SECRET_KEY" ]; then
            echo "ðŸ“ Creating new application secret key..."
            # Generate a random suffix to match Terraform naming convention
            RANDOM_SUFFIX=$(openssl rand -hex 4)
            SECRET_KEY_NAME="${RESOURCE_PREFIX}-secret-key-${RANDOM_SUFFIX}"
            
            aws secretsmanager create-secret \
              --name "$SECRET_KEY_NAME" \
              --description "Application secret key for $ENVIRONMENT" \
              --secret-string "$(openssl rand -base64 64)" \
              --region ${{ env.AWS_REGION }} \
              --tags '[{"Key":"Environment","Value":"'$ENVIRONMENT'"},{"Key":"Project","Value":"'$PROJECT_NAME'"},{"Key":"ManagedBy","Value":"github-actions"}]'
            echo "âœ… Created secret: $SECRET_KEY_NAME"
          else
            echo "âœ… Found existing secret key: $EXISTING_SECRET_KEY"
          fi

          # Create database password if it doesn't exist
          if [ -z "$EXISTING_DB_PASSWORD" ]; then
            echo "ðŸ“ Creating new database password..."
            # Generate a random suffix to match Terraform naming convention
            RANDOM_SUFFIX=$(openssl rand -hex 4)
            DB_PASSWORD_NAME="${RESOURCE_PREFIX}-db-password-${RANDOM_SUFFIX}"
            
            aws secretsmanager create-secret \
              --name "$DB_PASSWORD_NAME" \
              --description "Database password for $ENVIRONMENT" \
              --secret-string "$(openssl rand -base64 32)" \
              --region ${{ env.AWS_REGION }} \
              --tags '[{"Key":"Environment","Value":"'$ENVIRONMENT'"},{"Key":"Project","Value":"'$PROJECT_NAME'"},{"Key":"ManagedBy","Value":"github-actions"}]'
            echo "âœ… Created secret: $DB_PASSWORD_NAME"
          else
            echo "âœ… Found existing database password: $EXISTING_DB_PASSWORD"
          fi

          echo "ðŸŽ¯ Secret verification complete"

      - name: Create S3 Terraform Backend Bucket
        run: |
          # Create S3 bucket for Terraform state if it doesn't exist
          aws s3api head-bucket --bucket "hibiji-terraform-state" --region ${{ env.AWS_REGION }} || \
          aws s3api create-bucket \
            --bucket "hibiji-terraform-state" \
            --region ${{ env.AWS_REGION }} \
            --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}

          # Enable versioning
          aws s3api put-bucket-versioning \
            --bucket "hibiji-terraform-state" \
            --versioning-configuration Status=Enabled

          # Enable encryption
          aws s3api put-bucket-encryption \
            --bucket "hibiji-terraform-state" \
            --server-side-encryption-configuration '{
              "Rules": [
                {
                  "ApplyServerSideEncryptionByDefault": {
                    "SSEAlgorithm": "AES256"
                  }
                }
              ]
            }'

          # Apply tags
          aws s3api put-bucket-tagging \
            --bucket "hibiji-terraform-state" \
            --tagging '{"TagSet":[{"Key":"Environment","Value":"shared"},{"Key":"Project","Value":"hibiji"},{"Key":"ManagedBy","Value":"github-actions"}]}'

      - name: Import Existing Resources Before Apply
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}

          echo " Importing existing resources to prevent conflicts..."

          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="hibiji"

          # Import existing secrets
          SECRET_JWT_NAME="${PROJECT_NAME}-${ENVIRONMENT}-secret-key"
          SECRET_DB_NAME="${PROJECT_NAME}-${ENVIRONMENT}-db-password"

          # Look for existing secrets with pattern matching
          EXISTING_SECRET_KEY=$(aws secretsmanager list-secrets \
            --region ${{ env.AWS_REGION }} \
            --query "SecretList[?starts_with(Name, '${SECRET_JWT_NAME}')].Name" \
            --output text)

          if [ -n "$EXISTING_SECRET_KEY" ] && [ "$EXISTING_SECRET_KEY" != "None" ]; then
            echo " Importing existing secret key: $EXISTING_SECRET_KEY"
            terraform import aws_secretsmanager_secret.app_secret_key "$EXISTING_SECRET_KEY" || echo "âš ï¸ Secret key import failed or already in state"
          fi

          EXISTING_DB_PASSWORD=$(aws secretsmanager list-secrets \
            --region ${{ env.AWS_REGION }} \
            --query "SecretList[?starts_with(Name, '${SECRET_DB_NAME}')].Name" \
            --output text)

          if [ -n "$EXISTING_DB_PASSWORD" ] && [ "$EXISTING_DB_PASSWORD" != "None" ]; then
            echo " Importing existing database password: $EXISTING_DB_PASSWORD"
            terraform import aws_secretsmanager_secret.database_password "$EXISTING_DB_PASSWORD" || echo "âš ï¸ Database password import failed or already in state"
          fi

          # Import existing ECR repositories
          ECR_BACKEND_REPO="${PROJECT_NAME}-${MAIN_ENV}-backend"
          ECR_FRONTEND_REPO="${PROJECT_NAME}-${MAIN_ENV}-frontend"

          if aws ecr describe-repositories --repository-names "$ECR_BACKEND_REPO" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo " Importing existing backend ECR repository..."
            terraform import aws_ecr_repository.backend "$ECR_BACKEND_REPO" || echo "âš ï¸ Backend ECR repository import failed or already in state"
          fi

          if aws ecr describe-repositories --repository-names "$ECR_FRONTEND_REPO" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo " Importing existing frontend ECR repository..."
            terraform import aws_ecr_repository.frontend "$ECR_FRONTEND_REPO" || echo "âš ï¸ Frontend ECR repository import failed or already in state"
          fi

          # Import existing CloudWatch log groups
          LOG_GROUP_BACKEND="/ecs/${PROJECT_NAME}-${ENVIRONMENT}-backend"
          LOG_GROUP_FRONTEND="/ecs/${PROJECT_NAME}-${ENVIRONMENT}-frontend"

          if aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP_BACKEND" --region ${{ env.AWS_REGION }} --query 'logGroups[?logGroupName==`'"$LOG_GROUP_BACKEND"'`]' --output text | grep -q "$LOG_GROUP_BACKEND"; then
            echo " Importing existing backend log group..."
            terraform import aws_cloudwatch_log_group.backend_ecs "$LOG_GROUP_BACKEND" || echo "âš ï¸ Backend log group import failed or already in state"
          fi

          if aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP_FRONTEND" --region ${{ env.AWS_REGION }} --query 'logGroups[?logGroupName==`'"$LOG_GROUP_FRONTEND"'`]' --output text | grep -q "$LOG_GROUP_FRONTEND"; then
            echo " Importing existing frontend log group..."
            terraform import aws_cloudwatch_log_group.frontend_ecs "$LOG_GROUP_FRONTEND" || echo "âš ï¸ Frontend log group import failed or already in state"
          fi

          # Import existing VPC if it exists
          echo "ðŸ“¥ Checking for existing VPC..."
          EXISTING_VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=${PROJECT_NAME}-${MAIN_ENV}-vpc" \
            --query 'Vpcs[0].VpcId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ "$EXISTING_VPC_ID" != "None" ] && [ -n "$EXISTING_VPC_ID" ]; then
            echo " Importing existing VPC: $EXISTING_VPC_ID"
            terraform import aws_vpc.main "$EXISTING_VPC_ID" || echo "âš ï¸ VPC import failed or already in state"
          fi

          # Import existing ECS cluster if it exists
          CLUSTER_NAME="${PROJECT_NAME}-${ENVIRONMENT}-cluster"
          if aws ecs describe-clusters --clusters "$CLUSTER_NAME" --region ${{ env.AWS_REGION }} --query 'clusters[0].clusterName' --output text | grep -q "$CLUSTER_NAME"; then
            echo " Importing existing ECS cluster..."
            terraform import aws_ecs_cluster.main "$CLUSTER_NAME" || echo "âš ï¸ ECS cluster import failed or already in state"
          fi

          echo "âœ… Resource import completed"

      - name: Terraform Apply with Robust Strategy
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          echo "ðŸš€ Starting robust Terraform deployment strategy..."

          # Step 1: Refresh state to sync with actual AWS resources
          echo " Step 1: Refreshing Terraform state..."
          terraform refresh

          # Step 2: Create fresh plan
          echo "ðŸ“‹ Step 2: Creating fresh Terraform plan..."
          terraform plan -out=tfplan -detailed-exitcode || {
            echo "âš ï¸ Plan creation failed, attempting plan without detailed exit code..."
            terraform plan -out=tfplan
          }

          # Step 3: Apply with fallback strategies
          echo "ðŸš€ Step 3: Applying Terraform configuration..."

          # First attempt: Full apply
          if terraform apply -auto-approve tfplan; then
            echo "âœ… Full Terraform apply completed successfully!"
          else
            echo "âš ï¸ Full apply failed, trying targeted deployment..."
            
            # Second attempt: Targeted apply for core infrastructure
            echo "ðŸŽ¯ Attempting targeted infrastructure deployment..."
            
            # Apply core infrastructure components
            terraform apply -auto-approve -target=aws_vpc.main -target=aws_ecs_cluster.main -target=aws_lb.main || {
              echo "âš ï¸ Targeted infrastructure deployment failed, trying individual resources..."
              
              # Third attempt: Individual resource deployment
              echo "ðŸ”§ Attempting individual resource deployment..."
              
              # Apply VPC
              terraform apply -auto-approve -target=aws_vpc.main || echo "âš ï¸ VPC deployment failed"
              
              # Apply ECS cluster
              terraform apply -auto-approve -target=aws_ecs_cluster.main || echo "âš ï¸ ECS cluster deployment failed"
              
              # Apply load balancer
              terraform apply -auto-approve -target=aws_lb.main || echo "âš ï¸ Load balancer deployment failed"
              
              echo "âœ… Individual resource deployment completed"
            }
          fi

          # Step 4: Verify deployment
          echo "ðŸ” Step 4: Verifying deployment..."
          terraform output || echo "âš ï¸ Could not retrieve outputs"

          echo "ðŸŽ‰ Terraform deployment process completed!"

      - name: Get infrastructure outputs
        id: terraform-outputs
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          set -e
          echo "ðŸ” Retrieving Terraform outputs..."

          # Function to validate and clean terraform output
          get_terraform_output() {
            local output_name="$1"
            local raw_output
            
            # Get raw output
            raw_output=$(terraform output -raw "$output_name" 2>/dev/null || echo "")
            
            # Check if output contains warning patterns (multiline or box characters)
            if [[ "$raw_output" == *"Warning: No outputs found"* ]] || \
               [[ "$raw_output" == *"â•·"* ]] || \
               [[ "$raw_output" == *"â”‚"* ]] || \
               [[ "$raw_output" == *"â•µ"* ]] || \
               [[ "$raw_output" =~ $'\n' ]]; then
              echo ""  # Return empty if it's a warning or multiline
            else
              # Clean any remaining formatting and return single line
              echo "$raw_output" | tr -d '\r\n' | sed 's/\x1b\[[0-9;]*m//g'
            fi
          }

          # Get outputs safely
          ALB_DNS=$(get_terraform_output "alb_dns_name")
          CLUSTER_NAME=$(get_terraform_output "cluster_name")

          # Validate and report outputs
          if [ -z "$ALB_DNS" ]; then
            echo "âš ï¸  Warning: alb_dns_name output not found or invalid"
            echo " Available outputs:"
            terraform output 2>/dev/null | head -10 || echo "No outputs available"
            ALB_DNS=""
          else
            echo "âœ… Found ALB DNS: $ALB_DNS"
          fi

          if [ -z "$CLUSTER_NAME" ]; then
            echo "âš ï¸  Warning: ecs_cluster_name output not found or invalid"
            echo " Available outputs:"
            terraform output 2>/dev/null | head -10 || echo "No outputs available"
            CLUSTER_NAME=""
          else
            echo "âœ… Found Cluster Name: $CLUSTER_NAME"
          fi

          # Set GitHub Actions outputs (guaranteed single-line, safe format)
          echo "alb_dns=${ALB_DNS}" >> $GITHUB_OUTPUT
          echo "cluster_name=${CLUSTER_NAME}" >> $GITHUB_OUTPUT

          echo "ðŸŽ¯ Terraform outputs retrieved successfully"

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.detect-environment.outputs.environment }}
          path: build-artifacts/

      - name: Pre-flight Infrastructure Validation
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          echo "ðŸ” Pre-flight Infrastructure Validation"
          echo "========================================"

          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="hibiji"

          # Get Terraform outputs for validation
          CLUSTER_NAME=$(terraform output -raw cluster_name 2>/dev/null || echo "")
          ALB_DNS=$(terraform output -raw alb_dns_name 2>/dev/null || echo "")

          # 1. Validate ECS Cluster exists and is active
          echo "ðŸ” Checking ECS cluster..."
          if [ -z "$CLUSTER_NAME" ]; then
            echo "âŒ ECS cluster name not found in Terraform outputs"
            exit 1
          fi

          CLUSTER_STATUS=$(aws ecs describe-clusters \
            --clusters "$CLUSTER_NAME" \
            --region ${{ env.AWS_REGION }} \
            --query 'clusters[0].status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
            echo "âŒ ECS cluster $CLUSTER_NAME is not ACTIVE (status: $CLUSTER_STATUS)"
            exit 1
          fi
          echo "âœ… ECS cluster $CLUSTER_NAME is ACTIVE"

          # 2. Validate ECS services exist
          echo "ðŸ” Checking ECS services..."
          BACKEND_SERVICE="${PROJECT_NAME}-${ENVIRONMENT}-backend"
          FRONTEND_SERVICE="${PROJECT_NAME}-${ENVIRONMENT}-frontend"

          # Check backend service
          BACKEND_STATUS=$(aws ecs describe-services \
            --cluster "$CLUSTER_NAME" \
            --services "$BACKEND_SERVICE" \
            --region ${{ env.AWS_REGION }} \
            --query 'services[0].status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          if [ "$BACKEND_STATUS" != "ACTIVE" ]; then
            echo "âŒ Backend service $BACKEND_SERVICE not found or not ACTIVE (status: $BACKEND_STATUS)"
            exit 1
          fi
          echo "âœ… Backend service $BACKEND_SERVICE is ACTIVE"

          # Check frontend service
          FRONTEND_STATUS=$(aws ecs describe-services \
            --cluster "$CLUSTER_NAME" \
            --services "$FRONTEND_SERVICE" \
            --region ${{ env.AWS_REGION }} \
            --query 'services[0].status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          if [ "$FRONTEND_STATUS" != "ACTIVE" ]; then
            echo "âŒ Frontend service $FRONTEND_SERVICE not found or not ACTIVE (status: $FRONTEND_STATUS)"
            exit 1
          fi
          echo "âœ… Frontend service $FRONTEND_SERVICE is ACTIVE"

          # 3. Validate ECR repositories exist
          echo "ðŸ” Checking ECR repositories..."
          ECR_BACKEND_REPO="${PROJECT_NAME}-${MAIN_ENV}-backend"
          ECR_FRONTEND_REPO="${PROJECT_NAME}-${MAIN_ENV}-frontend"

          # Check backend repository
          aws ecr describe-repositories \
            --repository-names "$ECR_BACKEND_REPO" \
            --region ${{ env.AWS_REGION }} \
            --query 'repositories[0].repositoryName' \
            --output text >/dev/null 2>&1

          if [ $? -ne 0 ]; then
            echo "âŒ ECR repository $ECR_BACKEND_REPO not found"
            exit 1
          fi
          echo "âœ… ECR repository $ECR_BACKEND_REPO exists"

          # Check frontend repository  
          aws ecr describe-repositories \
            --repository-names "$ECR_FRONTEND_REPO" \
            --region ${{ env.AWS_REGION }} \
            --query 'repositories[0].repositoryName' \
            --output text >/dev/null 2>&1

          if [ $? -ne 0 ]; then
            echo "âŒ ECR repository $ECR_FRONTEND_REPO not found"
            exit 1
          fi
          echo "âœ… ECR repository $ECR_FRONTEND_REPO exists"

          # 4. Validate ECR images exist (if Build & Package succeeded)
          echo "ðŸ” Checking ECR images..."
          BACKEND_IMAGE_URI="${{ needs.detect-environment.outputs.ecr_registry }}/${ECR_BACKEND_REPO}:${{ github.sha }}"
          FRONTEND_IMAGE_URI="${{ needs.detect-environment.outputs.ecr_registry }}/${ECR_FRONTEND_REPO}:${{ github.sha }}"

          # Check backend image
          aws ecr describe-images \
            --repository-name "$ECR_BACKEND_REPO" \
            --image-ids imageTag=${{ github.sha }} \
            --region ${{ env.AWS_REGION }} >/dev/null 2>&1

          if [ $? -eq 0 ]; then
            echo "âœ… Backend image ${{ github.sha }} exists in ECR"
            echo "USE_REAL_IMAGES=true" >> $GITHUB_ENV
            echo "BACKEND_IMAGE_URI=$BACKEND_IMAGE_URI" >> $GITHUB_ENV
          else
            echo "âš ï¸ Backend image ${{ github.sha }} not found in ECR, will use nginx placeholder"
            echo "USE_REAL_IMAGES=false" >> $GITHUB_ENV
            echo "BACKEND_IMAGE_URI=nginx:latest" >> $GITHUB_ENV
          fi

          # Check frontend image
          aws ecr describe-images \
            --repository-name "$ECR_FRONTEND_REPO" \
            --image-ids imageTag=${{ github.sha }} \
            --region ${{ env.AWS_REGION }} >/dev/null 2>&1

          if [ $? -eq 0 ]; then
            echo "âœ… Frontend image ${{ github.sha }} exists in ECR"
            echo "FRONTEND_IMAGE_URI=$FRONTEND_IMAGE_URI" >> $GITHUB_ENV
          else
            echo "âš ï¸ Frontend image ${{ github.sha }} not found in ECR, will use nginx placeholder"
            echo "FRONTEND_IMAGE_URI=nginx:latest" >> $GITHUB_ENV
          fi

          echo "âœ… Infrastructure validation completed successfully"
