name: Digital Persona Platform - Unified CI/CD (Optimized v2)

on:
  push:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  pull_request:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  workflow_dispatch:
    inputs:
      force_deploy:
        description: "Force deployment even if tests fail"
        required: false
        default: false
        type: boolean
      skip_tests:
        description: "Skip test execution for emergency deployments"
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  security-events: write
  actions: read
  contents: read

env:
  AWS_REGION: us-west-1
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "20"
  DOMAIN: hibiji.com
  TERRAFORM_VERSION: "1.5.0"

# Prevent multiple runs from conflicting
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ===========================================
  # ENVIRONMENT DETECTION
  # ===========================================
  detect-environment:
    name: üîç Environment Detection
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      main_env: ${{ steps.env.outputs.main_env }}
      should_deploy: ${{ steps.env.outputs.should_deploy }}
      is_numbered_env: ${{ steps.env.outputs.is_numbered_env }}
      ecr_registry: ${{ steps.env.outputs.ecr_registry }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine Environment and AWS Registry
        id: env
        run: |
          # Determine environment based on branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENVIRONMENT="prod"
            MAIN_ENV="prod"
            SHOULD_DEPLOY="false"  # Main branch requires manual deployment
            IS_NUMBERED_ENV="false"
          elif [[ "${{ github.ref_name }}" =~ ^dev[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="dev"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^qa[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="qa"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^staging[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="staging"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^hotfix[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="hotfix"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          else
            echo "‚ùå Invalid branch name: ${{ github.ref_name }}"
            echo "Valid branches: main, dev01-dev99, qa01-qa99, staging01-staging99, hotfix01-hotfix99"
            exit 1
          fi

          # Get AWS Account ID dynamically
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)

          # Set ECR registry for later use
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"

          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "main_env=$MAIN_ENV" >> $GITHUB_OUTPUT
          echo "should_deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
          echo "is_numbered_env=$IS_NUMBERED_ENV" >> $GITHUB_OUTPUT
          echo "ecr_registry=$ECR_REGISTRY" >> $GITHUB_OUTPUT

          echo "üéØ Environment: $ENVIRONMENT"
          echo "Ô∏è  Main Environment: $MAIN_ENV"
          echo " Should Deploy: $SHOULD_DEPLOY"
          echo " ECR Registry: $ECR_REGISTRY"

  # ===========================================
  # PARALLEL CI PHASE (All run simultaneously)
  # ===========================================

  security-scan:
    name: Ô∏è Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.skip_tests != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Cache security scan results
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/trivy
            ~/.cache/semgrep
          key: ${{ runner.os }}-security-${{ hashFiles('**/requirements.txt', '**/package*.json') }}
          restore-keys: |
            ${{ runner.os }}-security-

      - name: Run Trivy vulnerability scanner
        id: trivy
        uses: aquasecurity/trivy-action@0.28.0
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "sarif"
          output: "trivy-results.sarif"
          severity: "CRITICAL,HIGH,MEDIUM"
          exit-code: "0"

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: "trivy-results.sarif"

      - name: Display Trivy scan summary
        if: always()
        run: |
          if [ -f "trivy-results.sarif" ]; then
            echo "üìä Trivy scan completed - check Security tab for detailed results"
            echo "üîç Scan summary:"
            cat trivy-results.sarif | jq -r '.runs[0].results | length' | xargs -I {} echo "Found {} potential issues"
          else
            echo "‚ö†Ô∏è Trivy results file not found"
          fi

      - name: Run TruffleHog secret scanner
        id: trufflehog
        uses: trufflesecurity/trufflehog@v3.82.13
        with:
          path: ./
          base: ${{ github.event.repository.default_branch }}
          head: ${{ github.sha }}
          extra_args: --exclude-paths=.trufflehogignore --exclude-detectors=postgres,mongodb,uri,github,cloudflareapitoken --only-verified
        continue-on-error: false

      - name: Handle TruffleHog failure
        if: failure() && steps.trufflehog.outcome == 'failure'
        run: |
          echo "üö® TruffleHog detected potential secrets!"
          echo "Review the scan results above and ensure no real secrets are committed."
          echo "If these are false positives, add them to .trufflehogignore"
          exit 1

      - name: Security scan summary
        if: always()
        run: |
          echo "üõ°Ô∏è Security Scan Summary"
          echo "======================="

          if [ "${{ steps.trivy.outcome }}" == "success" ]; then
            echo "‚úÖ Trivy vulnerability scan: PASSED"
          else
            echo "‚ùå Trivy vulnerability scan: FAILED"
          fi

          if [ "${{ steps.trufflehog.outcome }}" == "success" ]; then
            echo "‚úÖ TruffleHog secret scan: PASSED"
          else
            echo "‚ùå TruffleHog secret scan: FAILED"
          fi

          echo ""
          echo "üìä View detailed results in:"
          echo "   - Security tab: Repository ‚Üí Security ‚Üí Code scanning"
          echo "   - Job logs: Expand steps above for details"

  backend-tests:
    name: Backend Tests (${{ matrix.python-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.skip_tests != 'true'
    defaults:
      run:
        working-directory: ./python-ml-service
    strategy:
      matrix:
        python-version: ["3.11"]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Ensure pip cache directory exists
        run: mkdir -p ~/.cache/pip

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install --upgrade setuptools wheel
          pip install -r requirements.txt --use-pep517

      - name: Run tests
        run: |
          python -m pytest tests/ -v --cov=app --cov-report=xml

      - name: Upload coverage reports (with retry)
        if: always()
        run: |
          echo "üìä Attempting to upload coverage reports to Codecov..."

          # Function to upload with retry logic
          upload_coverage() {
            local max_attempts=3
            local attempt=1
            local wait_time=10
            
            while [ $attempt -le $max_attempts ]; do
              echo "üîÑ Upload attempt $attempt/$max_attempts..."
              
              # Check if coverage file exists
              if [ ! -f "./coverage.xml" ]; then
                echo "‚ö†Ô∏è Coverage file not found, skipping upload"
                return 0
              fi
              
              # Try to upload using curl with timeout and retry
              if curl --max-time 60 --retry 3 --retry-delay 5 \
                --retry-max-time 300 \
                --data-binary @./coverage.xml \
                -H "Content-Type: text/xml" \
                -H "X-Codecov-Token: ${{ secrets.CODECOV_TOKEN }}" \
                -H "X-Reduced-Redundancy: false" \
                -H "X-Reported-Job-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Number: ${{ github.run_number }}" \
                -H "X-Reported-Branch: ${{ github.ref_name }}" \
                -H "X-Reported-Commit-Sha: ${{ github.sha }}" \
                -H "X-Reported-Pull-Request: ${{ github.event.pull_request.number || '' }}" \
                -H "X-Reported-Job-Name: backend-coverage" \
                -H "X-Reported-Flags: backend" \
                "https://codecov.io/upload/v2" > /tmp/codecov_response.json 2>/tmp/codecov_error.log; then
                
                echo "‚úÖ Coverage upload successful!"
                cat /tmp/codecov_response.json
                return 0
              else
                echo "‚ùå Upload failed (attempt $attempt/$max_attempts)"
                echo "Error log:"
                cat /tmp/codecov_error.log
                
                if [ $attempt -lt $max_attempts ]; then
                  echo "‚è≥ Waiting $wait_time seconds before retry..."
                  sleep $wait_time
                  wait_time=$((wait_time * 2))  # Exponential backoff
                fi
                
                attempt=$((attempt + 1))
              fi
            done
            
            echo "‚ùå All upload attempts failed"
            return 1
          }

          # Attempt upload
          if upload_coverage; then
            echo "‚úÖ Coverage upload completed successfully"
          else
            echo "‚ö†Ô∏è Coverage upload failed, but continuing workflow"
            echo "This is a non-critical failure and won't block the deployment"
          fi

  frontend-tests:
    name: ‚öõÔ∏è Frontend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    if: github.event.inputs.skip_tests != 'true'
    defaults:
      run:
        working-directory: ./apps/web
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Ensure npm cache directory exists
        run: mkdir -p ~/.npm

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"
          cache-dependency-path: package-lock.json

      - name: Install dependencies
        run: npm ci

      - name: Check if test script exists
        id: check-tests
        run: |
          if npm run test --dry-run >/dev/null 2>&1; then
            echo "has_tests=true" >> $GITHUB_OUTPUT
          else
            echo "has_tests=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No test script found in package.json, skipping tests"
          fi

      - name: Run frontend tests
        if: steps.check-tests.outputs.has_tests == 'true'
        run: npm test -- --coverage --watchAll=false

      - name: Run linting and type checking (alternative to tests)
        if: steps.check-tests.outputs.has_tests == 'false'
        continue-on-error: true
        run: |
          echo "üîç Running linting and type checking instead of tests..."
          npm run lint --if-present || echo "‚ö†Ô∏è Linting failed, continuing..."
          echo "üîß Running isolated type checking on src directory only..."
          npx tsc --noEmit --skipLibCheck src/**/*.ts src/**/*.tsx || echo "‚ö†Ô∏è Type checking failed, continuing..."

      - name: Upload coverage reports (with retry)
        if: always() && steps.check-tests.outputs.has_tests == 'true'
        run: |
          echo "üìä Attempting to upload frontend coverage reports to Codecov..."

          # Function to upload with retry logic
          upload_coverage() {
            local max_attempts=3
            local attempt=1
            local wait_time=10
            
            while [ $attempt -le $max_attempts ]; do
              echo "üîÑ Upload attempt $attempt/$max_attempts..."
              
              # Check if coverage directory exists
              if [ ! -d "./coverage" ]; then
                echo "‚ö†Ô∏è Coverage directory not found, skipping upload"
                return 0
              fi
              
              # Check if lcov.info exists
              if [ ! -f "./coverage/lcov.info" ]; then
                echo "‚ö†Ô∏è lcov.info file not found, skipping upload"
                return 0
              fi
              
              # Try to upload using curl with timeout and retry
              if curl --max-time 60 --retry 3 --retry-delay 5 \
                --retry-max-time 300 \
                --form "file=@./coverage/lcov.info" \
                -H "X-Codecov-Token: ${{ secrets.CODECOV_TOKEN }}" \
                -H "X-Reduced-Redundancy: false" \
                -H "X-Reported-Job-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Id: ${{ github.run_id }}" \
                -H "X-Reported-Build-Number: ${{ github.run_number }}" \
                -H "X-Reported-Branch: ${{ github.ref_name }}" \
                -H "X-Reported-Commit-Sha: ${{ github.sha }}" \
                -H "X-Reported-Pull-Request: ${{ github.event.pull_request.number || '' }}" \
                -H "X-Reported-Job-Name: frontend-coverage" \
                -H "X-Reported-Flags: frontend" \
                "https://codecov.io/upload/v2" > /tmp/codecov_response.json 2>/tmp/codecov_error.log; then
                
                echo "‚úÖ Frontend coverage upload successful!"
                cat /tmp/codecov_response.json
                return 0
              else
                echo "‚ùå Upload failed (attempt $attempt/$max_attempts)"
                echo "Error log:"
                cat /tmp/codecov_error.log
                
                if [ $attempt -lt $max_attempts ]; then
                  echo "‚è≥ Waiting $wait_time seconds before retry..."
                  sleep $wait_time
                  wait_time=$((wait_time * 2))  # Exponential backoff
                fi
                
                attempt=$((attempt + 1))
              fi
            done
            
            echo "‚ùå All upload attempts failed"
            return 1
          }

          # Attempt upload
          if upload_coverage; then
            echo "‚úÖ Frontend coverage upload completed successfully"
          else
            echo "‚ö†Ô∏è Frontend coverage upload failed, but continuing workflow"
            echo "This is a non-critical failure and won't block the deployment"
          fi

  dependency-scan:
    name: üì¶ Dependency Scan
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: github.event.inputs.skip_tests != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run dependency vulnerability scan
        uses: pypa/gh-action-pip-audit@v1.0.8
        with:
          inputs: python-ml-service/requirements.txt

  terraform-plan:
    name: üèóÔ∏è Terraform Plan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [detect-environment]
    if: needs.detect-environment.outputs.should_deploy == 'true'
    outputs:
      plan_id: ${{ steps.plan.outputs.plan_id }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Terraform Init
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}
          terraform init

      - name: Terraform Plan
        id: plan
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}
          terraform plan -out=tfplan -detailed-exitcode
          echo "plan_id=tfplan" >> $GITHUB_OUTPUT

  # ===========================================
  # BUILD & PACKAGE PHASE
  # ===========================================
  build-and-package:
    name: üèóÔ∏è Build & Package
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs:
      [
        detect-environment,
        security-scan,
        backend-tests,
        frontend-tests,
        dependency-scan,
      ]
    if: |
      always() && 
      needs.detect-environment.result == 'success' &&
      (needs.security-scan.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.backend-tests.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.frontend-tests.result == 'success' || github.event.inputs.skip_tests == 'true') &&
      (needs.dependency-scan.result != 'cancelled' || github.event.inputs.skip_tests == 'true' || github.event.inputs.force_deploy == 'true')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Clean up disk space
        run: |
          # Remove unnecessary files to free up space
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"
          df -h

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repositories if they don't exist
        run: |
          # Create backend repository
          aws ecr describe-repositories --repository-names hibiji-backend --region ${{ env.AWS_REGION }} || \
          aws ecr create-repository \
            --repository-name hibiji-backend \
            --region ${{ env.AWS_REGION }} \
            --tags Key=Environment,Value=${{ needs.detect-environment.outputs.environment }} \
                   Key=Project,Value=hibiji \
                   Key=ManagedBy,Value=github-actions

          # Create frontend repository  
          aws ecr describe-repositories --repository-names hibiji-frontend --region ${{ env.AWS_REGION }} || \
          aws ecr create-repository \
            --repository-name hibiji-frontend \
            --region ${{ env.AWS_REGION }} \
            --tags Key=Environment,Value=${{ needs.detect-environment.outputs.environment }} \
                   Key=Project,Value=hibiji \
                   Key=ManagedBy,Value=github-actions

      - name: Build and push backend Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          platforms: linux/amd64
          push: true
          tags: |
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-backend:${{ github.sha }}
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-backend:latest
          # Use registry cache to avoid disk space issues
          cache-from: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-backend:cache
          cache-to: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-backend:cache,mode=max

      - name: Build and push frontend Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./apps/web/Dockerfile
          platforms: linux/amd64
          push: true
          tags: |
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-frontend:${{ github.sha }}
            ${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-frontend:latest
          # Use registry cache to avoid disk space issues
          cache-from: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-frontend:cache
          cache-to: type=registry,ref=${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-frontend:cache,mode=max

      - name: Create build artifacts
        run: |
          mkdir -p build-artifacts
          echo "${{ github.sha }}" > build-artifacts/commit-sha.txt
          echo "${{ needs.detect-environment.outputs.environment }}" > build-artifacts/environment.txt
          echo "${{ needs.detect-environment.outputs.ecr_registry }}" > build-artifacts/ecr-registry.txt

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ needs.detect-environment.outputs.environment }}
          path: build-artifacts/

  # ===========================================
  # DEPLOYMENT PHASE
  # ===========================================
  deploy:
    name: üöÄ Deploy to ${{ needs.detect-environment.outputs.environment }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [detect-environment, terraform-plan, build-and-package]
    if: |
      always() && 
      needs.detect-environment.outputs.should_deploy == 'true' &&
      needs.detect-environment.result == 'success' &&
      needs.terraform-plan.result == 'success' &&
      (needs.build-and-package.result == 'success' || github.event.inputs.force_deploy == 'true')
    environment:
      name: ${{ needs.detect-environment.outputs.environment }}
      url: https://${{ needs.detect-environment.outputs.environment }}.${{ env.DOMAIN }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Download Terraform Plan
        uses: actions/download-artifact@v4
        with:
          name: terraform-plan-${{ needs.detect-environment.outputs.environment }}
          path: terraform/environments/${{ needs.detect-environment.outputs.main_env }}/

      - name: Create AWS Secrets if they don't exist
        run: |
          # Get the environment-specific prefix
          RESOURCE_PREFIX="hibiji-${{ needs.detect-environment.outputs.environment }}"

          # Check if secrets already exist (they may have random suffixes from Terraform)
          echo "üîç Checking for existing secrets..."

          # Look for existing secret key (with pattern matching)
          EXISTING_SECRET_KEY=$(aws secretsmanager list-secrets \
            --region ${{ env.AWS_REGION }} \
            --query "SecretList[?starts_with(Name, '${RESOURCE_PREFIX}-secret-key')].Name" \
            --output text)

          # Look for existing database password (with pattern matching)
          EXISTING_DB_PASSWORD=$(aws secretsmanager list-secrets \
            --region ${{ env.AWS_REGION }} \
            --query "SecretList[?starts_with(Name, '${RESOURCE_PREFIX}-db-password')].Name" \
            --output text)

          # Create app secret key if it doesn't exist
          if [ -z "$EXISTING_SECRET_KEY" ]; then
            echo "üìù Creating new application secret key..."
            # Generate a random suffix to match Terraform naming convention
            RANDOM_SUFFIX=$(openssl rand -hex 4)
            SECRET_KEY_NAME="${RESOURCE_PREFIX}-secret-key-${RANDOM_SUFFIX}"
            
            aws secretsmanager create-secret \
              --name "$SECRET_KEY_NAME" \
              --description "Application secret key for ${{ needs.detect-environment.outputs.environment }}" \
              --secret-string "$(openssl rand -base64 64)" \
              --region ${{ env.AWS_REGION }} \
              --tags '[{"Key":"Environment","Value":"${{ needs.detect-environment.outputs.environment }}"},{"Key":"Project","Value":"hibiji"},{"Key":"ManagedBy","Value":"github-actions"}]'
            echo "‚úÖ Created secret: $SECRET_KEY_NAME"
          else
            echo "‚úÖ Found existing secret key: $EXISTING_SECRET_KEY"
          fi

          # Create database password if it doesn't exist
          if [ -z "$EXISTING_DB_PASSWORD" ]; then
            echo "üìù Creating new database password..."
            # Generate a random suffix to match Terraform naming convention
            RANDOM_SUFFIX=$(openssl rand -hex 4)
            DB_PASSWORD_NAME="${RESOURCE_PREFIX}-db-password-${RANDOM_SUFFIX}"
            
            aws secretsmanager create-secret \
              --name "$DB_PASSWORD_NAME" \
              --description "Database password for ${{ needs.detect-environment.outputs.environment }}" \
              --secret-string "$(openssl rand -base64 32)" \
              --region ${{ env.AWS_REGION }} \
              --tags '[{"Key":"Environment","Value":"${{ needs.detect-environment.outputs.environment }}"},{"Key":"Project","Value":"hibiji"},{"Key":"ManagedBy","Value":"github-actions"}]'
            echo "‚úÖ Created secret: $DB_PASSWORD_NAME"
          else
            echo "‚úÖ Found existing database password: $EXISTING_DB_PASSWORD"
          fi

          echo "üéØ Secret verification complete"

      - name: Create S3 Terraform Backend Bucket
        run: |
          # Create S3 bucket for Terraform state if it doesn't exist
          aws s3api head-bucket --bucket "hibiji-terraform-state" --region ${{ env.AWS_REGION }} || \
          aws s3api create-bucket \
            --bucket "hibiji-terraform-state" \
            --region ${{ env.AWS_REGION }} \
            --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}

          # Enable versioning
          aws s3api put-bucket-versioning \
            --bucket "hibiji-terraform-state" \
            --versioning-configuration Status=Enabled

          # Enable encryption
          aws s3api put-bucket-encryption \
            --bucket "hibiji-terraform-state" \
            --server-side-encryption-configuration '{
              "Rules": [
                {
                  "ApplyServerSideEncryptionByDefault": {
                    "SSEAlgorithm": "AES256"
                  }
                }
              ]
            }'

          # Apply tags
          aws s3api put-bucket-tagging \
            --bucket "hibiji-terraform-state" \
            --tagging '{"TagSet":[{"Key":"Environment","Value":"shared"},{"Key":"Project","Value":"hibiji"},{"Key":"ManagedBy","Value":"github-actions"}]}'

      - name: Terraform Init
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}
          
          # Clean up any existing state issues
          echo "üßπ Cleaning up potential state issues..."
          rm -f .terraform.lock.hcl
          rm -rf .terraform/
          
          # Create S3 backend bucket if it doesn't exist
          echo "üì¶ Ensuring S3 backend bucket exists..."
          aws s3api head-bucket --bucket "hibiji-terraform-state" --region ${{ env.AWS_REGION }} || \
          aws s3api create-bucket \
            --bucket "hibiji-terraform-state" \
            --region ${{ env.AWS_REGION }} \
            --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}
          
          # Enable versioning on the bucket
          aws s3api put-bucket-versioning \
            --bucket "hibiji-terraform-state" \
            --versioning-configuration Status=Enabled
          
          # Check if corrupted state exists and backup/remove it
          echo "üîç Checking for corrupted state file..."
          STATE_KEY="${{ needs.detect-environment.outputs.main_env }}/terraform.tfstate"
          
          if aws s3api head-object --bucket "hibiji-terraform-state" --key "$STATE_KEY" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo "‚ö†Ô∏è Found existing state file, backing up and removing corrupted state..."
            aws s3api copy-object \
              --bucket "hibiji-terraform-state" \
              --copy-source "hibiji-terraform-state/$STATE_KEY" \
              --key "${STATE_KEY}.backup.$(date +%Y%m%d-%H%M%S)" \
              --region ${{ env.AWS_REGION }}
            
            # Remove the corrupted state file
            aws s3api delete-object \
              --bucket "hibiji-terraform-state" \
              --key "$STATE_KEY" \
              --region ${{ env.AWS_REGION }}
            
            echo "‚úÖ Corrupted state file backed up and removed"
          else
            echo "‚úÖ No existing state file found"
          fi
          
          # Initialize with explicit backend configuration
          echo " Initializing Terraform..."
          terraform init \
            -backend-config="bucket=hibiji-terraform-state" \
            -backend-config="key=$STATE_KEY" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -reconfigure

      - name: Terraform Apply
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          echo " Applying Terraform configuration..."

          # First attempt - normal apply
          if ! terraform apply -auto-approve tfplan; then
            echo "‚ö†Ô∏è Terraform apply failed, checking for CloudWatch Log Group conflicts..."
            
            # Check if failure was due to existing CloudWatch Log Groups
            if terraform apply -auto-approve tfplan 2>&1 | grep -q "ResourceAlreadyExistsException.*CloudWatch.*Log Group"; then
              echo "üîç Detected existing CloudWatch Log Groups, attempting to import them..."
              
              # Import existing log groups if they exist
              LOG_GROUP_BACKEND="/ecs/hibiji-${{ needs.detect-environment.outputs.environment }}-backend"
              LOG_GROUP_FRONTEND="/ecs/hibiji-${{ needs.detect-environment.outputs.environment }}-frontend"
              
              # Try to import backend log group
              if aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP_BACKEND" --region ${{ env.AWS_REGION }} --query 'logGroups[0].logGroupName' --output text | grep -q "$LOG_GROUP_BACKEND"; then
                echo " Importing existing backend log group: $LOG_GROUP_BACKEND"
                terraform import aws_cloudwatch_log_group.backend_ecs "$LOG_GROUP_BACKEND" || echo "‚ö†Ô∏è Backend log group import failed or already in state"
              fi
              
              # Try to import frontend log group  
              if aws logs describe-log-groups --log-group-name-prefix "$LOG_GROUP_FRONTEND" --region ${{ env.AWS_REGION }} --query 'logGroups[0].logGroupName' --output text | grep -q "$LOG_GROUP_FRONTEND"; then
                echo " Importing existing frontend log group: $LOG_GROUP_FRONTEND"
                terraform import aws_cloudwatch_log_group.frontend_ecs "$LOG_GROUP_FRONTEND" || echo "‚ö†Ô∏è Frontend log group import failed or already in state"
              fi
              
              # Retry apply after import
              echo " Retrying Terraform apply after importing existing resources..."
              terraform apply -auto-approve tfplan
            else
              echo "‚ùå Terraform apply failed for reasons other than CloudWatch Log Group conflicts"
              exit 1
            fi
          else
            echo "‚úÖ Terraform apply completed successfully"
          fi

      - name: Get infrastructure outputs
        id: terraform-outputs
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          set -e
          echo "üîç Retrieving Terraform outputs..."

          # Function to validate and clean terraform output
          get_terraform_output() {
            local output_name="$1"
            local raw_output
            
            # Get raw output
            raw_output=$(terraform output -raw "$output_name" 2>/dev/null || echo "")
            
            # Check if output contains warning patterns (multiline or box characters)
            if [[ "$raw_output" == *"Warning: No outputs found"* ]] || \
               [[ "$raw_output" == *"‚ï∑"* ]] || \
               [[ "$raw_output" == *"‚îÇ"* ]] || \
               [[ "$raw_output" == *"‚ïµ"* ]] || \
               [[ "$raw_output" =~ $'\n' ]]; then
              echo ""  # Return empty if it's a warning or multiline
            else
              # Clean any remaining formatting and return single line
              echo "$raw_output" | tr -d '\r\n' | sed 's/\x1b\[[0-9;]*m//g'
            fi
          }

          # Get outputs safely
          ALB_DNS=$(get_terraform_output "alb_dns_name")
          CLUSTER_NAME=$(get_terraform_output "cluster_name")

          # Validate and report outputs
          if [ -z "$ALB_DNS" ]; then
            echo "‚ö†Ô∏è  Warning: alb_dns_name output not found or invalid"
            echo " Available outputs:"
            terraform output 2>/dev/null | head -10 || echo "No outputs available"
            ALB_DNS=""
          else
            echo "‚úÖ Found ALB DNS: $ALB_DNS"
          fi

          if [ -z "$CLUSTER_NAME" ]; then
            echo "‚ö†Ô∏è  Warning: ecs_cluster_name output not found or invalid"
            echo " Available outputs:"
            terraform output 2>/dev/null | head -10 || echo "No outputs available"
            CLUSTER_NAME=""
          else
            echo "‚úÖ Found Cluster Name: $CLUSTER_NAME"
          fi

          # Set GitHub Actions outputs (guaranteed single-line, safe format)
          echo "alb_dns=${ALB_DNS}" >> $GITHUB_OUTPUT
          echo "cluster_name=${CLUSTER_NAME}" >> $GITHUB_OUTPUT

          echo "üéØ Terraform outputs retrieved successfully"

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.detect-environment.outputs.environment }}
          path: build-artifacts/

      - name: Pre-flight Infrastructure Validation
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          echo "üîç Pre-flight Infrastructure Validation"
          echo "========================================"

          # Get Terraform outputs for validation
          CLUSTER_NAME=$(terraform output -raw cluster_name 2>/dev/null || echo "")
          ALB_DNS=$(terraform output -raw alb_dns_name 2>/dev/null || echo "")

          # 1. Validate ECS Cluster exists and is active
          echo "üîç Checking ECS cluster..."
          if [ -z "$CLUSTER_NAME" ]; then
            echo "‚ùå ECS cluster name not found in Terraform outputs"
            exit 1
          fi

          CLUSTER_STATUS=$(aws ecs describe-clusters \
            --clusters "$CLUSTER_NAME" \
            --region ${{ env.AWS_REGION }} \
            --query 'clusters[0].status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
            echo "‚ùå ECS cluster $CLUSTER_NAME is not ACTIVE (status: $CLUSTER_STATUS)"
            exit 1
          fi
          echo "‚úÖ ECS cluster $CLUSTER_NAME is ACTIVE"

          # 2. Validate ECS services exist
          echo "üîç Checking ECS services..."
          BACKEND_SERVICE="hibiji-${{ needs.detect-environment.outputs.environment }}-backend"
          FRONTEND_SERVICE="hibiji-${{ needs.detect-environment.outputs.environment }}-frontend"

          # Check backend service
          BACKEND_STATUS=$(aws ecs describe-services \
            --cluster "$CLUSTER_NAME" \
            --services "$BACKEND_SERVICE" \
            --region ${{ env.AWS_REGION }} \
            --query 'services[0].status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          if [ "$BACKEND_STATUS" != "ACTIVE" ]; then
            echo "‚ùå Backend service $BACKEND_SERVICE not found or not ACTIVE (status: $BACKEND_STATUS)"
            exit 1
          fi
          echo "‚úÖ Backend service $BACKEND_SERVICE is ACTIVE"

          # Check frontend service
          FRONTEND_STATUS=$(aws ecs describe-services \
            --cluster "$CLUSTER_NAME" \
            --services "$FRONTEND_SERVICE" \
            --region ${{ env.AWS_REGION }} \
            --query 'services[0].status' \
            --output text 2>/dev/null || echo "NOT_FOUND")

          if [ "$FRONTEND_STATUS" != "ACTIVE" ]; then
            echo "‚ùå Frontend service $FRONTEND_SERVICE not found or not ACTIVE (status: $FRONTEND_STATUS)"
            exit 1
          fi
          echo "‚úÖ Frontend service $FRONTEND_SERVICE is ACTIVE"

          # 3. Validate ECR repositories exist
          echo "üîç Checking ECR repositories..."
          ECR_BACKEND_REPO="hibiji-backend"
          ECR_FRONTEND_REPO="hibiji-frontend"

          # Check backend repository
          aws ecr describe-repositories \
            --repository-names "$ECR_BACKEND_REPO" \
            --region ${{ env.AWS_REGION }} \
            --query 'repositories[0].repositoryName' \
            --output text >/dev/null 2>&1

          if [ $? -ne 0 ]; then
            echo "‚ùå ECR repository $ECR_BACKEND_REPO not found"
            exit 1
          fi
          echo "‚úÖ ECR repository $ECR_BACKEND_REPO exists"

          # Check frontend repository  
          aws ecr describe-repositories \
            --repository-names "$ECR_FRONTEND_REPO" \
            --region ${{ env.AWS_REGION }} \
            --query 'repositories[0].repositoryName' \
            --output text >/dev/null 2>&1

          if [ $? -ne 0 ]; then
            echo "‚ùå ECR repository $ECR_FRONTEND_REPO not found"
            exit 1
          fi
          echo "‚úÖ ECR repository $ECR_FRONTEND_REPO exists"

          # 4. Validate ECR images exist (if Build & Package succeeded)
          echo "üîç Checking ECR images..."
          BACKEND_IMAGE_URI="${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-backend:${{ github.sha }}"
          FRONTEND_IMAGE_URI="${{ needs.detect-environment.outputs.ecr_registry }}/hibiji-frontend:${{ github.sha }}"

          # Check backend image
          aws ecr describe-images \
            --repository-name "$ECR_BACKEND_REPO" \
            --image-ids imageTag=${{ github.sha }} \
            --region ${{ env.AWS_REGION }} >/dev/null 2>&1

          if [ $? -eq 0 ]; then
            echo "‚úÖ Backend image ${{ github.sha }} exists in ECR"
            echo "USE_REAL_IMAGES=true" >> $GITHUB_ENV
            echo "BACKEND_IMAGE_URI=$BACKEND_IMAGE_URI" >> $GITHUB_ENV
          else
            echo "‚ö†Ô∏è Backend image ${{ github.sha }} not found in ECR, will use nginx placeholder"
            echo "USE_REAL_IMAGES=false" >> $GITHUB_ENV
            echo "BACKEND_IMAGE_URI=nginx:latest" >> $GITHUB_ENV
          fi

          # Check frontend image
          aws ecr describe-images \
            --repository-name "$ECR_FRONTEND_REPO" \
            --image-ids imageTag=${{ github.sha }} \
            --region ${{ env.AWS_REGION }} >/dev/null 2>&1

          if [ $? -eq 0 ]; then
            echo "‚úÖ Frontend image ${{ github.sha }} exists in ECR"
            echo "FRONTEND_IMAGE_URI=$FRONTEND_IMAGE_URI" >> $GITHUB_ENV
          else
            echo "‚ö†Ô∏è Frontend image ${{ github.sha }} not found in ECR, will use nginx placeholder"
            echo "FRONTEND_IMAGE_URI=nginx:latest" >> $GITHUB_ENV
          fi

          # 5. Validate CloudWatch Log Groups exist
          echo "üîç Checking CloudWatch Log Groups..."
          BAC
