name: Cleanup Sub-Environment

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Sub-environment to clean up (e.g., dev01, qa02, staging03)"
        required: true
        type: string
      force_cleanup:
        description: "Force cleanup without confirmation"
        required: false
        default: false
        type: boolean
      dry_run:
        description: "Perform a dry run (show what would be deleted)"
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-west-1

jobs:
  cleanup:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Validate Environment
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"

          # Validate environment name format
          if [[ ! "$ENVIRONMENT" =~ ^(dev|qa|staging|hotfix)[0-9][0-9]$ ]]; then
            echo "❌ Invalid environment format: $ENVIRONMENT"
            echo "Valid formats: dev01-dev99, qa01-qa99, staging01-staging99, hotfix01-hotfix99"
            exit 1
          fi

          # Extract main environment
          MAIN_ENV=$(echo "$ENVIRONMENT" | sed 's/[0-9]*$//')

          echo "✅ Environment validation passed"
          echo "Sub-environment: $ENVIRONMENT"
          echo "Main environment: $MAIN_ENV"

          echo "ENVIRONMENT=$ENVIRONMENT" >> $GITHUB_ENV
          echo "MAIN_ENV=$MAIN_ENV" >> $GITHUB_ENV

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: Terraform Destroy
        working-directory: terraform/environments/${{ env.MAIN_ENV }}
        run: |
          echo "🧹 Destroying infrastructure for ${{ env.ENVIRONMENT }}..."

          # Initialize Terraform
          terraform init

          # Create tfvars file
          cat > environment.auto.tfvars << EOF
          environment = "${{ env.MAIN_ENV }}"
          sub_environment = "${{ env.ENVIRONMENT }}"
          project_name = "dpp"
          domain_name = "hibiji.com"
          aws_region = "${{ env.AWS_REGION }}"
          alert_emails = ["alerts@maras.co"]
          EOF

          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            echo "🔍 DRY RUN: Showing what would be destroyed..."
            terraform plan -destroy -var-file="environment.auto.tfvars"
          else
            echo "🚨 DESTROYING infrastructure..."
            
            if [ "${{ github.event.inputs.force_cleanup }}" = "true" ]; then
              terraform destroy -auto-approve -var-file="environment.auto.tfvars"
            else
              echo "❌ Manual approval required. Set force_cleanup=true to proceed."
              exit 1
            fi
          fi

      - name: Clean up orphaned AWS resources
        if: github.event.inputs.dry_run != 'true' && github.event.inputs.force_cleanup == 'true'
        run: |
          echo "🧹 Cleaning up orphaned AWS resources for ${{ env.ENVIRONMENT }}..."

          ENVIRONMENT="${{ env.ENVIRONMENT }}"
          MAIN_ENV="${{ env.MAIN_ENV }}"
          PROJECT_NAME="dpp"

          # Clean up Lambda functions
          echo "🧹 Cleaning up Lambda functions..."
          LAMBDA_FUNCTIONS=$(aws lambda list-functions \
            --query "Functions[?starts_with(FunctionName, '${MAIN_ENV}-${ENVIRONMENT}')].FunctionName" \
            --output text)

          for func in $LAMBDA_FUNCTIONS; do
            if [ -n "$func" ] && [ "$func" != "None" ]; then
              echo "🗑️ Deleting Lambda function: $func"
              aws lambda delete-function --function-name "$func" || echo "⚠️ Failed to delete Lambda function: $func"
            fi
          done

          # Clean up API Gateway v2 APIs
          echo "🧹 Cleaning up API Gateway v2 APIs..."
          API_IDS=$(aws apigatewayv2 get-apis \
            --query "Items[?starts_with(Name, '${MAIN_ENV}-${ENVIRONMENT}')].ApiId" \
            --output text)

          for api_id in $API_IDS; do
            if [ -n "$api_id" ] && [ "$api_id" != "None" ]; then
              echo "🗑️ Deleting API Gateway: $api_id"
              aws apigatewayv2 delete-api --api-id "$api_id" || echo "⚠️ Failed to delete API Gateway: $api_id"
            fi
          done

          # Clean up S3 buckets
          echo "🧹 Cleaning up S3 buckets..."
          S3_BUCKETS=$(aws s3api list-buckets \
            --query "Buckets[?starts_with(Name, '${MAIN_ENV}-${ENVIRONMENT}')].Name" \
            --output text)

          for bucket in $S3_BUCKETS; do
            if [ -n "$bucket" ] && [ "$bucket" != "None" ]; then
              echo "🗑️ Emptying and deleting S3 bucket: $bucket"
              aws s3 rm s3://$bucket --recursive || echo "⚠️ Failed to empty bucket: $bucket"
              aws s3api delete-bucket --bucket "$bucket" || echo "⚠️ Failed to delete bucket: $bucket"
            fi
          done

          # Clean up CloudWatch Log Groups
          echo "🧹 Cleaning up CloudWatch Log Groups..."
          LOG_GROUPS=$(aws logs describe-log-groups \
            --query "logGroups[?contains(logGroupName, '${ENVIRONMENT}')].logGroupName" \
            --output text)

          for log_group in $LOG_GROUPS; do
            if [ -n "$log_group" ] && [ "$log_group" != "None" ]; then
              echo "🗑️ Deleting log group: $log_group"
              aws logs delete-log-group --log-group-name "$log_group" || echo "⚠️ Failed to delete log group: $log_group"
            fi
          done

          # Clean up AWS Batch resources (proper order: Job Definitions → Job Queues → Compute Environments)
          echo "🧹 Cleaning up AWS Batch Job Definitions..."
          JOB_DEFINITIONS=$(aws batch describe-job-definitions \
            --query "jobDefinitions[?starts_with(jobDefinitionName, '${MAIN_ENV}-${ENVIRONMENT}')].jobDefinitionArn" \
            --output text)

          for job_def in $JOB_DEFINITIONS; do
            if [ -n "$job_def" ] && [ "$job_def" != "None" ]; then
              echo "🗑️ Deregistering Batch job definition: $job_def"
              aws batch deregister-job-definition --job-definition "$job_def" || echo "⚠️ Failed to deregister job definition: $job_def"
            fi
          done

          echo "🧹 Cleaning up AWS Batch Job Queues..."
          JOB_QUEUES=$(aws batch describe-job-queues \
            --query "jobQueues[?starts_with(jobQueueName, '${MAIN_ENV}-${ENVIRONMENT}')].jobQueueName" \
            --output text)

          for queue in $JOB_QUEUES; do
            if [ -n "$queue" ] && [ "$queue" != "None" ]; then
              echo "🔄 Disabling Batch job queue: $queue"
              aws batch update-job-queue --job-queue "$queue" --state DISABLED || echo "⚠️ Failed to disable job queue: $queue"
              
              echo "⏳ Waiting for job queue to be disabled..."
              sleep 30
              
              echo "🗑️ Deleting Batch job queue: $queue"
              aws batch delete-job-queue --job-queue "$queue" || echo "⚠️ Failed to delete job queue: $queue"
            fi
          done

          echo "🧹 Cleaning up AWS Batch Compute Environments..."
          COMPUTE_ENVS=$(aws batch describe-compute-environments \
            --query "computeEnvironments[?starts_with(computeEnvironmentName, '${MAIN_ENV}-${ENVIRONMENT}')].computeEnvironmentName" \
            --output text)

          for env in $COMPUTE_ENVS; do
            if [ -n "$env" ] && [ "$env" != "None" ]; then
              echo "🔄 Disabling Batch compute environment: $env"
              aws batch update-compute-environment --compute-environment "$env" --state DISABLED || echo "⚠️ Failed to disable compute environment: $env"
              
              echo "⏳ Waiting for compute environment to be disabled..."
              sleep 60
              
              echo "🗑️ Deleting Batch compute environment: $env"
              aws batch delete-compute-environment --compute-environment "$env" || echo "⚠️ Failed to delete compute environment: $env"
            fi
          done

          # Clean up SQS Queues (including DLQ)
          echo "🧹 Cleaning up SQS Queues..."
          SQS_QUEUES=$(aws sqs list-queues \
            --queue-name-prefix "${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}" \
            --query "QueueUrls" --output text)

          for queue_url in $SQS_QUEUES; do
            if [ -n "$queue_url" ] && [ "$queue_url" != "None" ]; then
              echo "🗑️ Deleting SQS queue: $queue_url"
              aws sqs delete-queue --queue-url "$queue_url" || echo "⚠️ Failed to delete SQS queue: $queue_url"
            fi
          done

          # Clean up ECR Repositories  
          echo "🧹 Cleaning up ECR Repositories..."
          ECR_REPOS=$(aws ecr describe-repositories \
            --query "repositories[?starts_with(repositoryName, '${MAIN_ENV}-${ENVIRONMENT}')].repositoryName" \
            --output text)

          for repo in $ECR_REPOS; do
            if [ -n "$repo" ] && [ "$repo" != "None" ]; then
              echo "🗑️ Emptying ECR repository: $repo"
              # Delete all images first
              IMAGES=$(aws ecr list-images --repository-name "$repo" --query 'imageIds[*]' --output json)
              if [ "$IMAGES" != "[]" ] && [ -n "$IMAGES" ]; then
                aws ecr batch-delete-image --repository-name "$repo" --image-ids "$IMAGES" || echo "⚠️ Failed to delete images from: $repo"
              fi
              
              echo "🗑️ Deleting ECR repository: $repo"
              aws ecr delete-repository --repository-name "$repo" || echo "⚠️ Failed to delete ECR repository: $repo"
            fi
          done

          # Clean up RDS Proxy endpoints
          echo "🧹 Cleaning up RDS Proxy endpoints..."
          RDS_PROXIES=$(aws rds describe-db-proxies \
            --query "DBProxies[?starts_with(DBProxyName, '${MAIN_ENV}-${ENVIRONMENT}')].DBProxyName" \
            --output text)

          for proxy in $RDS_PROXIES; do
            if [ -n "$proxy" ] && [ "$proxy" != "None" ]; then
              echo "🗑️ Deleting RDS Proxy: $proxy"
              aws rds delete-db-proxy --db-proxy-name "$proxy" || echo "⚠️ Failed to delete RDS proxy: $proxy"
            fi
          done

          # Clean up Secrets Manager secrets
          echo "🧹 Cleaning up Secrets Manager secrets..."
          SECRETS=$(aws secretsmanager list-secrets \
            --query "SecretList[?starts_with(Name, '${MAIN_ENV}-${ENVIRONMENT}')].Name" \
            --output text)

          for secret in $SECRETS; do
            if [ -n "$secret" ] && [ "$secret" != "None" ]; then
              echo "🗑️ Deleting secret: $secret"
              aws secretsmanager delete-secret --secret-id "$secret" --force-delete-without-recovery || echo "⚠️ Failed to delete secret: $secret"
            fi
          done

          # Clean up RDS instances and clusters
          echo "🧹 Cleaning up RDS resources..."
          RDS_CLUSTERS=$(aws rds describe-db-clusters \
            --query "DBClusters[?starts_with(DBClusterIdentifier, '${ENVIRONMENT}')].DBClusterIdentifier" \
            --output text)

          for cluster in $RDS_CLUSTERS; do
            if [ -n "$cluster" ] && [ "$cluster" != "None" ]; then
              echo "🗑️ Deleting RDS cluster: $cluster"
              # Delete cluster instances first
              CLUSTER_INSTANCES=$(aws rds describe-db-clusters \
                --db-cluster-identifier "$cluster" \
                --query "DBClusters[0].DBClusterMembers[*].DBInstanceIdentifier" \
                --output text)
              
              for instance in $CLUSTER_INSTANCES; do
                if [ -n "$instance" ] && [ "$instance" != "None" ]; then
                  echo "🗑️ Deleting RDS instance: $instance"
                  aws rds delete-db-instance --db-instance-identifier "$instance" --skip-final-snapshot || echo "⚠️ Failed to delete RDS instance: $instance"
                fi
              done
              
              # Wait for instances to be deleted before deleting cluster
              echo "⏳ Waiting for instances to be deleted..."
              sleep 60
              
              aws rds delete-db-cluster --db-cluster-identifier "$cluster" --skip-final-snapshot || echo "⚠️ Failed to delete RDS cluster: $cluster"
            fi
          done

          # Clean up CloudFront distributions
          echo "🧹 Cleaning up CloudFront distributions..."
          DISTRIBUTIONS=$(aws cloudfront list-distributions \
            --query "DistributionList.Items[?contains(Aliases.Items || [''], '${ENVIRONMENT}')].{Id:Id,DomainName:DomainName}" \
            --output text)

          if [ -n "$DISTRIBUTIONS" ] && [ "$DISTRIBUTIONS" != "None" ]; then
            echo "$DISTRIBUTIONS" | while read id domain; do
              if [ -n "$id" ] && [ "$id" != "None" ]; then
                echo "🗑️ Disabling CloudFront distribution: $id ($domain)"
                
                # Get current distribution config
                aws cloudfront get-distribution-config --id "$id" --query 'DistributionConfig' > dist_config.json
                ETAG=$(aws cloudfront get-distribution-config --id "$id" --query 'ETag' --output text)
                
                # Disable distribution
                jq '.Enabled = false' dist_config.json > dist_config_disabled.json
                aws cloudfront update-distribution --id "$id" --distribution-config file://dist_config_disabled.json --if-match "$ETAG" || echo "⚠️ Failed to disable distribution: $id"
                
                echo "⏳ Distribution disabled. Manual deletion required after propagation."
              fi
            done
          fi

          # Verification: Check for any remaining AWS Batch resources
          echo "🔍 Verifying AWS Batch cleanup..."
          REMAINING_QUEUES=$(aws batch describe-job-queues \
            --query "jobQueues[?starts_with(jobQueueName, '${MAIN_ENV}-${ENVIRONMENT}')].jobQueueName" \
            --output text)
          REMAINING_COMPUTE_ENVS=$(aws batch describe-compute-environments \
            --query "computeEnvironments[?starts_with(computeEnvironmentName, '${MAIN_ENV}-${ENVIRONMENT}')].computeEnvironmentName" \
            --output text)

          if [ -n "$REMAINING_QUEUES" ] && [ "$REMAINING_QUEUES" != "None" ]; then
            echo "⚠️ Warning: Some Batch job queues may still be deleting: $REMAINING_QUEUES"
            echo "💡 These should finish deleting automatically within a few minutes"
          fi

          if [ -n "$REMAINING_COMPUTE_ENVS" ] && [ "$REMAINING_COMPUTE_ENVS" != "None" ]; then
            echo "⚠️ Warning: Some Batch compute environments may still be deleting: $REMAINING_COMPUTE_ENVS"
            echo "💡 These should finish deleting automatically within a few minutes"
          fi

          echo "✅ Orphaned resource cleanup completed!"

      - name: Cleanup Summary
        if: always()
        run: |
          echo "🎯 Cleanup Summary"
          echo "=================="
          echo "Environment: ${{ env.ENVIRONMENT }}"
          echo "Main Environment: ${{ env.MAIN_ENV }}"
          echo "Dry Run: ${{ github.event.inputs.dry_run }}"
          echo "Force Cleanup: ${{ github.event.inputs.force_cleanup }}"
          echo ""

          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            echo "✅ Dry run completed - no resources were deleted"
          elif [ "${{ github.event.inputs.force_cleanup }}" = "true" ]; then
            echo "✅ Cleanup completed for environment: ${{ env.ENVIRONMENT }}"
            echo ""
            echo "📋 Resources cleaned up:"
            echo "  • Terraform-managed infrastructure"
            echo "  • AWS Batch job definitions, queues, and compute environments"
            echo "  • SQS queues (main queue + dead letter queue)"
            echo "  • ECR repositories (ML service container images)"
            echo "  • RDS Proxy endpoints"
            echo "  • Lambda functions"
            echo "  • API Gateway v2 APIs"
            echo "  • S3 buckets"
            echo "  • CloudWatch Log Groups"
            echo "  • Secrets Manager secrets"
            echo "  • RDS clusters and instances"
            echo "  • CloudFront distributions (disabled)"
            echo ""
            echo "⚠️ Note: CloudFront distributions require manual deletion after propagation"
          else
            echo "❌ Cleanup was not performed (force_cleanup not enabled)"
          fi
