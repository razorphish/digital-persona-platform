name: Deploy Serverless Architecture

on:
  push:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  pull_request:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  workflow_dispatch:
    inputs:
      force_deploy:
        description: "Force deployment even if tests fail"
        required: false
        default: false
        type: boolean
      skip_tests:
        description: "Skip test execution for emergency deployments"
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  security-events: write
  actions: read
  contents: read

env:
  AWS_REGION: us-west-1
  NODE_VERSION: 20
  # Remove hardcoded DOMAIN - will be determined dynamically

jobs:
  # ===========================================
  # ENVIRONMENT DETECTION
  # ===========================================
  detect-environment:
    name: üîç Environment Detection
    runs-on: ubuntu-latest
    timeout-minutes: 5
    # Use workflow-specific concurrency group
    concurrency:
      group: serverless-deployment-${{ github.ref_name }}
      cancel-in-progress: true
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      main_env: ${{ steps.env.outputs.main_env }}
      should_deploy: ${{ steps.env.outputs.should_deploy }}
      is_numbered_env: ${{ steps.env.outputs.is_numbered_env }}
      api_url: ${{ steps.env.outputs.api_url }}
      s3_bucket: ${{ steps.env.outputs.s3_bucket }}
      function_name: ${{ steps.env.outputs.function_name }}
      log_group_name: ${{ steps.env.outputs.log_group_name }}
      domain: ${{ steps.env.outputs.domain }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine Environment and Resources
        id: env
        run: |
          # Determine environment based on branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENVIRONMENT="prod"
            MAIN_ENV="prod"
            SHOULD_DEPLOY="false"  # Main branch requires manual deployment
            IS_NUMBERED_ENV="false"
          elif [[ "${{ github.ref_name }}" =~ ^dev[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="dev"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^qa[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="qa"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^staging[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="staging"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^hotfix[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="hotfix"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          else
            echo "‚ùå Invalid branch name: ${{ github.ref_name }}"
            echo "Valid branches: main, dev01-dev99, qa01-qa99, staging01-staging99, hotfix01-hotfix99"
            exit 1
          fi

          # Generate dynamic resource names
          FUNCTION_NAME="$MAIN_ENV-$ENVIRONMENT-dpp-api"
          S3_BUCKET="$MAIN_ENV-$ENVIRONMENT-dpp-website"
          LOG_GROUP_NAME="/aws/lambda/$FUNCTION_NAME"

          # Generate API URL dynamically based on environment pattern
          # Use a dynamic domain based on environment
          if [[ "$ENVIRONMENT" == "prod" ]]; then
            DOMAIN="hibiji.com"
            API_URL="https://api.$DOMAIN"
          else
            DOMAIN="hibiji.com"
            API_URL="https://$ENVIRONMENT.$DOMAIN"
          fi

          echo "Environment: $ENVIRONMENT"
          echo "Main Environment: $MAIN_ENV"
          echo "Should Deploy: $SHOULD_DEPLOY"
          echo "Is Numbered Environment: $IS_NUMBERED_ENV"
          echo "Function Name: $FUNCTION_NAME"
          echo "S3 Bucket: $S3_BUCKET"
          echo "Log Group: $LOG_GROUP_NAME"
          echo "API URL: $API_URL"
          echo "Domain: $DOMAIN"

          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "main_env=$MAIN_ENV" >> $GITHUB_OUTPUT
          echo "should_deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
          echo "is_numbered_env=$IS_NUMBERED_ENV" >> $GITHUB_OUTPUT
          echo "api_url=$API_URL" >> $GITHUB_OUTPUT
          echo "s3_bucket=$S3_BUCKET" >> $GITHUB_OUTPUT
          echo "function_name=$FUNCTION_NAME" >> $GITHUB_OUTPUT
          echo "log_group_name=$LOG_GROUP_NAME" >> $GITHUB_OUTPUT
          echo "domain=$DOMAIN" >> $GITHUB_OUTPUT

  # =================================
  # Build and Test
  # =================================
  build-and-test:
    name: Build and Test
    runs-on: ubuntu-latest
    needs: detect-environment
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Run linting
        run: npm run lint --if-present

      - name: Run type checking
        run: npm run type-check --if-present

      - name: Run tests
        run: npm run test --if-present

  # =================================
  # Build Frontend for Static Export
  # =================================
  build-frontend:
    name: Build Frontend
    runs-on: ubuntu-latest
    needs: [detect-environment, build-and-test]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    outputs:
      frontend-hash: ${{ steps.frontend-hash.outputs.hash }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Build shared packages
        run: |
          npm run build --workspace=@digital-persona/shared
          npm run build --workspace=@digital-persona/database

      - name: Build frontend for static export
        env:
          NODE_ENV: production
          NEXT_BUILD_EXPORT: true
          # Use dynamic API URL from environment detection
          NEXT_PUBLIC_API_URL: ${{ needs.detect-environment.outputs.api_url }}
        run: |
          npm run build --workspace=apps/web

      - name: Generate frontend hash
        id: frontend-hash
        run: |
          cd apps/web/out
          HASH=$(find . -type f -name "*.html" -o -name "*.js" -o -name "*.css" | xargs sha256sum | sort | sha256sum | cut -d' ' -f1)
          echo "hash=$HASH" >> $GITHUB_OUTPUT

      - name: Upload frontend artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-${{ needs.detect-environment.outputs.environment }}-${{ steps.frontend-hash.outputs.hash }}
          path: apps/web/out/
          retention-days: 7

  # =================================
  # Build Backend for Lambda
  # =================================
  build-backend:
    name: Build Backend
    runs-on: ubuntu-latest
    needs: [detect-environment, build-and-test]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    outputs:
      backend-hash: ${{ steps.backend-hash.outputs.hash }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Build shared packages
        run: |
          npm run build --workspace=@digital-persona/shared
          npm run build --workspace=@digital-persona/database

      - name: Build backend for Lambda
        run: |
          echo "üöÄ Building Lambda function with esbuild bundling..."
          npm run build:lambda --workspace=apps/server

      - name: Generate backend hash
        id: backend-hash
        run: |
          cd apps/server/lambda-dist
          HASH=$(find . -type f | xargs sha256sum | sort | sha256sum | cut -d' ' -f1)
          echo "hash=$HASH" >> $GITHUB_OUTPUT

      - name: Upload backend artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backend-${{ needs.detect-environment.outputs.environment }}-${{ steps.backend-hash.outputs.hash }}
          path: apps/server/lambda-dist/
          retention-days: 7

  # =================================
  # Deploy Infrastructure
  # =================================
  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [detect-environment, build-frontend, build-backend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: Terraform Init
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}

          # Clean up any existing state issues
          echo "üßπ Cleaning up potential state issues..."
          rm -f .terraform.lock.hcl
          rm -rf .terraform/

          # Create S3 backend bucket if it doesn't exist
          echo "üì¶ Ensuring S3 backend bucket exists..."
          aws s3api head-bucket --bucket "hibiji-terraform-state" --region ${{ env.AWS_REGION }} || \
          aws s3api create-bucket \
            --bucket "hibiji-terraform-state" \
            --region ${{ env.AWS_REGION }} \
            --create-bucket-configuration LocationConstraint=${{ env.AWS_REGION }}

          # Enable versioning on the bucket
          aws s3api put-bucket-versioning \
            --bucket "hibiji-terraform-state" \
            --versioning-configuration Status=Enabled

          # Check if corrupted state exists and backup/remove it
          echo "üîç Checking for corrupted state file..."
          STATE_KEY="${{ needs.detect-environment.outputs.main_env }}/serverless/terraform.tfstate"

          if aws s3api head-object --bucket "hibiji-terraform-state" --key "$STATE_KEY" --region ${{ env.AWS_REGION }} >/dev/null 2>&1; then
            echo "‚ö†Ô∏è Found existing state file, backing up and removing corrupted state..."
            aws s3api copy-object \
              --bucket "hibiji-terraform-state" \
              --copy-source "hibiji-terraform-state/$STATE_KEY" \
              --key "${STATE_KEY}.backup.$(date +%Y%m%d-%H%M%S)" \
              --region ${{ env.AWS_REGION }}
            
            # Remove the corrupted state file
            aws s3api delete-object \
              --bucket "hibiji-terraform-state" \
              --key "$STATE_KEY" \
              --region ${{ env.AWS_REGION }}
            
            echo "‚úÖ Corrupted state file backed up and removed"
          else
            echo "‚úÖ No existing state file found"
          fi

          # Initialize with explicit backend configuration
          echo " Initializing Terraform..."
          terraform init \
            -backend-config="bucket=hibiji-terraform-state" \
            -backend-config="key=$STATE_KEY" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -reconfigure

      - name: Terraform Plan
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}
          terraform plan -out=tfplan

      - name: Import Existing Resources (IAM Roles & CloudWatch Log Groups)
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}

          echo "üîç Checking and importing existing resources..."

          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="dpp"

          # Import ECS execution role if it exists in AWS but not in state
          ECS_EXECUTION_ROLE="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-ecs-execution"
          if aws iam get-role --role-name "$ECS_EXECUTION_ROLE" >/dev/null 2>&1; then
            if ! terraform state show aws_iam_role.ecs_execution >/dev/null 2>&1; then
              echo "üì• Importing ECS execution role: $ECS_EXECUTION_ROLE"
              terraform import aws_iam_role.ecs_execution "$ECS_EXECUTION_ROLE" || echo "‚ö†Ô∏è Import failed (may not have permissions)"
            fi
          fi

          # Import ECS task role if it exists in AWS but not in state  
          ECS_TASK_ROLE="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-ecs-task"
          if aws iam get-role --role-name "$ECS_TASK_ROLE" >/dev/null 2>&1; then
            if ! terraform state show aws_iam_role.ecs_task >/dev/null 2>&1; then
              echo " Importing ECS task role: $ECS_TASK_ROLE"
              terraform import aws_iam_role.ecs_task "$ECS_TASK_ROLE" || echo "‚ö†Ô∏è Import failed (may not have permissions)"
            fi
          fi

          # Import Lambda execution role if it exists in AWS but not in state
          LAMBDA_EXECUTION_ROLE="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-lambda-execution"
          if aws iam get-role --role-name "$LAMBDA_EXECUTION_ROLE" >/dev/null 2>&1; then
            if ! terraform state show module.lambda_backend.aws_iam_role.lambda_execution >/dev/null 2>&1; then
              echo "üì• Importing Lambda execution role: $LAMBDA_EXECUTION_ROLE"
              terraform import module.lambda_backend.aws_iam_role.lambda_execution "$LAMBDA_EXECUTION_ROLE" || echo "‚ö†Ô∏è Import failed (may not have permissions)"
            fi
          fi

          # Import CloudWatch Log Group if it exists in AWS but not in state
          LAMBDA_LOG_GROUP="${{ needs.detect-environment.outputs.log_group_name }}"
          if aws logs describe-log-groups --log-group-name-prefix "$LAMBDA_LOG_GROUP" --query 'logGroups[?logGroupName==`'"$LAMBDA_LOG_GROUP"'`]' --output text | grep -q "$LAMBDA_LOG_GROUP"; then
            if ! terraform state show module.lambda_backend.aws_cloudwatch_log_group.lambda_logs >/dev/null 2>&1; then
              echo "üì• Importing CloudWatch Log Group: $LAMBDA_LOG_GROUP"
              terraform import module.lambda_backend.aws_cloudwatch_log_group.lambda_logs "$LAMBDA_LOG_GROUP" || echo "‚ö†Ô∏è Import failed (may not have permissions)"
            fi
          fi

          # Import API Gateway Log Group if it exists in AWS but not in state
          API_LOG_GROUP="/aws/apigateway/${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}"
          if aws logs describe-log-groups --log-group-name-prefix "$API_LOG_GROUP" --query 'logGroups[?logGroupName==`'"$API_LOG_GROUP"'`]' --output text | grep -q "$API_LOG_GROUP"; then
            if ! terraform state show module.api_gateway.aws_cloudwatch_log_group.api_gateway >/dev/null 2>&1; then
              echo "üì• Importing API Gateway Log Group: $API_LOG_GROUP"
              terraform import module.api_gateway.aws_cloudwatch_log_group.api_gateway "$API_LOG_GROUP" || echo "‚ö†Ô∏è Import failed (may not have permissions)"
            fi
          fi

          echo "‚úÖ Resource import step completed"

      - name: Import Existing Resources Before Apply
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}

          echo "üîÑ Importing existing resources to prevent conflicts..."

          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="dpp"

          # Function to check if resource is already in state
          check_resource_in_state() {
            local resource_address="$1"
            terraform state show "$resource_address" >/dev/null 2>&1
            return $?
          }

          # Function to check if AWS resource exists
          check_aws_resource() {
            local resource_type="$1"
            local resource_identifier="$2"
            
            case "$resource_type" in
              "secret")
                aws secretsmanager describe-secret --secret-id "$resource_identifier" --region ${{ env.AWS_REGION }} >/dev/null 2>&1
                ;;
              "s3_bucket")
                aws s3api head-bucket --bucket "$resource_identifier" --region ${{ env.AWS_REGION }} >/dev/null 2>&1
                ;;
              "log_group")
                aws logs describe-log-groups --log-group-name-prefix "$resource_identifier" --region ${{ env.AWS_REGION }} --query 'logGroups[?logGroupName==`'"$resource_identifier"'`]' --output text | grep -q "$resource_identifier"
                ;;
              "vpc")
                aws ec2 describe-vpcs --filters "Name=tag:Name,Values=$resource_identifier" --query 'Vpcs[0].VpcId' --output text --region ${{ env.AWS_REGION }} 2>/dev/null | grep -v "None"
                ;;
              "oac")
                aws cloudfront list-origin-access-controls --query "OriginAccessControlList.Items[?Name=='$resource_identifier'].Id" --output text 2>/dev/null | grep -v "None"
                ;;
            esac
          }

          # Function to safely import resource
          safe_import() {
            local resource_address="$1"
            local aws_resource_id="$2"
            local resource_type="$3"
            local description="$4"
            
            echo "üîç Checking $description..."
            
            if check_resource_in_state "$resource_address"; then
              echo "‚úÖ $description already in Terraform state"
              return 0
            fi
            
            if check_aws_resource "$resource_type" "$aws_resource_id"; then
              echo "üì• Importing $description: $aws_resource_id"
              if terraform import "$resource_address" "$aws_resource_id"; then
                echo "‚úÖ Successfully imported $description"
              else
                echo "‚ö†Ô∏è Failed to import $description (may not have permissions)"
                return 1
              fi
            else
              echo "‚ÑπÔ∏è $description does not exist in AWS, will be created"
            fi
          }

          # Import existing secrets
          SECRET_JWT_NAME="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-jwt-secret"
          SECRET_DB_NAME="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-database-password"

          safe_import "aws_secretsmanager_secret.jwt_secret" "$SECRET_JWT_NAME" "secret" "JWT secret"
          safe_import "aws_secretsmanager_secret.database_password" "$SECRET_DB_NAME" "secret" "Database password secret"

          # Import existing S3 buckets
          BUCKET_UPLOADS="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-uploads"
          BUCKET_WEBSITE="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-website"
          BUCKET_BUILDS="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-builds"
          BUCKET_LAMBDA_DEPLOYMENTS="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-lambda-deployments"

          safe_import "aws_s3_bucket.uploads" "$BUCKET_UPLOADS" "s3_bucket" "Uploads bucket"
          safe_import "module.s3_website.aws_s3_bucket.website" "$BUCKET_WEBSITE" "s3_bucket" "Website bucket"
          safe_import "module.s3_website.aws_s3_bucket.builds" "$BUCKET_BUILDS" "s3_bucket" "Builds bucket"
          safe_import "module.lambda_backend.aws_s3_bucket.lambda_deployments" "$BUCKET_LAMBDA_DEPLOYMENTS" "s3_bucket" "Lambda deployments bucket"

          # Import existing CloudWatch log groups
          LOG_GROUP_API="/aws/apigateway/${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}"
          LOG_GROUP_LAMBDA="/aws/lambda/${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-api"
          LOG_GROUP_BACKEND_ECS="/ecs/hibiji-${ENVIRONMENT}-backend"
          LOG_GROUP_FRONTEND_ECS="/ecs/hibiji-${ENVIRONMENT}-frontend"

          safe_import "module.api_gateway.aws_cloudwatch_log_group.api_gateway" "$LOG_GROUP_API" "log_group" "API Gateway log group"
          safe_import "module.lambda_backend.aws_cloudwatch_log_group.lambda_logs" "$LOG_GROUP_LAMBDA" "log_group" "Lambda log group"
          safe_import "aws_cloudwatch_log_group.backend_ecs" "$LOG_GROUP_BACKEND_ECS" "log_group" "Backend ECS log group"
          safe_import "aws_cloudwatch_log_group.frontend_ecs" "$LOG_GROUP_FRONTEND_ECS" "log_group" "Frontend ECS log group"

          # Import existing VPC if it exists
          echo "üì• Checking for existing VPC..."
          VPC_NAME="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-vpc"
          EXISTING_VPC_ID=$(aws ec2 describe-vpcs \
            --filters "Name=tag:Name,Values=$VPC_NAME" \
            --query 'Vpcs[0].VpcId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")

          if [ "$EXISTING_VPC_ID" != "None" ] && [ -n "$EXISTING_VPC_ID" ]; then
            safe_import "aws_vpc.main" "$EXISTING_VPC_ID" "vpc" "VPC"
          fi

          # Import existing CloudFront Origin Access Control if it exists
          OAC_NAME="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-oac"
          EXISTING_OAC_ID=$(aws cloudfront list-origin-access-controls --query "OriginAccessControlList.Items[?Name=='$OAC_NAME'].Id" --output text 2>/dev/null || echo "")

          if [ "$EXISTING_OAC_ID" != "None" ] && [ -n "$EXISTING_OAC_ID" ]; then
            safe_import "module.s3_website.aws_cloudfront_origin_access_control.website" "$EXISTING_OAC_ID" "oac" "CloudFront Origin Access Control"
          fi

          # Note: Route53 zone is configured as a data source (data.aws_route53_zone.main) 
          # and doesn't need to be imported since it's not managed by Terraform
          echo "‚ÑπÔ∏è Route53 zone is configured as data source - no import needed"

          echo "‚úÖ Resource import completed"

      - name: Terraform Apply with Robust Fallback Strategy
        run: |
          cd terraform/environments/${{ needs.detect-environment.outputs.main_env }}

          echo "üöÄ Starting robust Terraform deployment strategy..."

          # Step 1: Validate state integrity
          echo "üîç Step 1: Validating Terraform state integrity..."
          if ! terraform validate; then
            echo "‚ùå Terraform configuration validation failed"
            exit 1
          fi

          # Step 2: Refresh state to sync with actual AWS resources
          echo "üîÑ Step 2: Refreshing Terraform state..."
          if terraform refresh -lock-timeout=300s; then
            echo "‚úÖ State refresh completed successfully"
          else
            echo "‚ö†Ô∏è State refresh failed, attempting state unlock..."
            terraform force-unlock -force || echo "‚ö†Ô∏è Unable to unlock state"
            # Retry refresh after unlock
            terraform refresh -lock-timeout=300s || echo "‚ö†Ô∏è State refresh still failing"
          fi

          # Step 3: Create fresh plan with detailed output
          echo "üìã Step 3: Creating fresh Terraform plan..."
          terraform plan -out=tfplan -detailed-exitcode > plan.log 2>&1
          PLAN_EXIT_CODE=$?

          case $PLAN_EXIT_CODE in
            0)
              echo "‚úÖ No changes required - infrastructure is up to date"
              ;;
            1)
              echo "‚ùå Terraform plan failed"
              cat plan.log
              exit 1
              ;;
            2)
              echo "üìù Changes detected - proceeding with apply"
              ;;
            *)
              echo "‚ùå Unexpected plan exit code: $PLAN_EXIT_CODE"
              cat plan.log
              exit 1
              ;;
          esac

          # Step 4: Apply with multiple fallback strategies
          if [ $PLAN_EXIT_CODE -eq 2 ]; then
            echo "üöÄ Step 4: Applying Terraform configuration..."

            # First attempt: Full apply with timeout
            echo "üéØ Attempt 1: Full Terraform apply..."
            if timeout 1800 terraform apply -auto-approve -lock-timeout=300s tfplan; then
              echo "‚úÖ Full Terraform apply completed successfully!"
            else
              echo "‚ö†Ô∏è Full apply failed, trying targeted deployment..."
              
              # Second attempt: Core infrastructure first
              echo "üèóÔ∏è Attempt 2: Core infrastructure deployment..."
              
              # Apply VPC and networking first
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_vpc.main \
                -target=aws_subnet.private \
                -target=aws_internet_gateway.main \
                -target=aws_security_group.database \
                -target=aws_security_group.lambda || echo "‚ö†Ô∏è VPC deployment issues"
              
              # Apply secrets and database
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_secretsmanager_secret.jwt_secret \
                -target=aws_secretsmanager_secret.database_password \
                -target=aws_secretsmanager_secret_version.jwt_secret \
                -target=aws_secretsmanager_secret_version.database_password \
                -target=aws_db_subnet_group.database \
                -target=aws_rds_cluster.database \
                -target=aws_rds_cluster_instance.database || echo "‚ö†Ô∏è Database deployment issues"
              
              # Apply S3 buckets
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_s3_bucket.uploads \
                -target=module.s3_website \
                -target=module.lambda_backend.aws_s3_bucket.lambda_deployments || echo "‚ö†Ô∏è S3 deployment issues"
              
              # Apply serverless components
              terraform apply -auto-approve -lock-timeout=300s \
                -target=module.lambda_backend \
                -target=module.api_gateway || echo "‚ö†Ô∏è Serverless deployment issues"
              
              # Apply Route53 records
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_route53_record.api \
                -target=aws_route53_record.website || echo "‚ö†Ô∏è DNS deployment issues"
              
              # Final attempt: Apply remaining resources
              echo "üîÑ Final attempt: Applying any remaining resources..."
              terraform apply -auto-approve -lock-timeout=300s || echo "‚ö†Ô∏è Some resources may need manual intervention"
            fi
          fi

          # Step 5: Verify deployment and get outputs
          echo "üîç Step 5: Verifying deployment..."
          if terraform output > outputs.log 2>&1; then
            echo "‚úÖ Deployment outputs:"
            cat outputs.log
          else
            echo "‚ö†Ô∏è Could not retrieve all outputs:"
            cat outputs.log
          fi

          # Step 6: Validate critical resources
          echo "üîç Step 6: Validating critical resources..."

          # Check if Lambda function exists
          LAMBDA_NAME=$(terraform output -raw lambda_function_name 2>/dev/null || echo "")
          if [ -n "$LAMBDA_NAME" ]; then
            if aws lambda get-function --function-name "$LAMBDA_NAME" >/dev/null 2>&1; then
              echo "‚úÖ Lambda function '$LAMBDA_NAME' is accessible"
            else
              echo "‚ö†Ô∏è Lambda function '$LAMBDA_NAME' may not be ready yet"
            fi
          fi

          # Check if API Gateway exists
          API_URL=$(terraform output -raw api_url 2>/dev/null || echo "")
          if [ -n "$API_URL" ]; then
            echo "‚úÖ API Gateway URL: $API_URL"
          else
            echo "‚ö†Ô∏è API Gateway URL not available in outputs"
          fi

          echo "üéâ Terraform deployment process completed!"

  # =================================
  # Deploy Frontend
  # =================================
  deploy-frontend:
    name: Deploy Frontend
    runs-on: ubuntu-latest
    needs: [detect-environment, deploy-infrastructure, build-frontend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download frontend artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-${{ needs.detect-environment.outputs.environment }}-${{ needs.build-frontend.outputs.frontend-hash }}

      - name: Verify frontend artifacts
        run: |
          echo " Verifying frontend artifacts..."
          ls -la
          if [ -d "out" ]; then
            echo "‚úÖ Frontend out directory found"
            ls -la out/
          else
            echo "‚ùå Frontend out directory not found, checking current directory"
            ls -la
            echo "üìÅ Creating minimal frontend structure..."
            mkdir -p out
            echo "<html><body><h1>Frontend Deployment</h1><p>Static files will be deployed here.</p></body></html>" > out/index.html
          fi

      - name: Deploy to S3
        run: |
          # Use dynamic S3 bucket name from environment detection
          echo "üöÄ Deploying to S3 bucket: ${{ needs.detect-environment.outputs.s3_bucket }}"

          # Check if out directory exists
          if [ ! -d "out" ]; then
            echo "‚ùå out directory not found, creating minimal structure"
            mkdir -p out
            echo "<html><body><h1>Frontend Deployment</h1><p>Static files will be deployed here.</p></body></html>" > out/index.html
          fi

          # Deploy to S3
          aws s3 sync out/ s3://${{ needs.detect-environment.outputs.s3_bucket }} --delete

      - name: Invalidate CloudFront cache
        run: |
          # Use dynamic domain name from environment detection
          DOMAIN_NAME="${{ needs.detect-environment.outputs.environment }}.${{ needs.detect-environment.outputs.domain }}"
          echo " Invalidating CloudFront cache for domain: $DOMAIN_NAME"

          DISTRIBUTION_ID=$(aws cloudfront list-distributions --query "DistributionList.Items[?Aliases.Items[?contains(@, '$DOMAIN_NAME')]].Id" --output text)
          if [ "$DISTRIBUTION_ID" != "None" ] && [ "$DISTRIBUTION_ID" != "" ]; then
            echo " Invalidating CloudFront cache for distribution: $DISTRIBUTION_ID"
            aws cloudfront create-invalidation --distribution-id $DISTRIBUTION_ID --paths "/*"
          else
            echo "‚ö†Ô∏è No CloudFront distribution found for domain: $DOMAIN_NAME"
          fi

  # =================================
  # Deploy Backend
  # =================================
  deploy-backend:
    name: Deploy Backend
    runs-on: ubuntu-latest
    needs: [detect-environment, deploy-infrastructure, build-backend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download backend artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-${{ needs.detect-environment.outputs.environment }}-${{ needs.build-backend.outputs.backend-hash }}

      - name: Create Lambda deployment package
        run: |
          echo "üì¶ Creating Lambda deployment package from bundled output..."
          echo "üìÅ Current directory contents:"
          ls -la

          # The artifacts are downloaded to the current directory
          # Check if we have the bundled files
          if [ ! -f "index.js" ]; then
            echo "‚ùå index.js not found in current directory"
            echo "üìÅ Available files:"
            find . -name "*.js" -o -name "*.json" | head -10
            exit 1
          fi

          # Create deployment zip from current directory (which contains the bundled output)
          echo "üì¶ Creating deployment zip from bundled files..."
          zip -r lambda-deployment.zip . -x "*.DS_Store*" "*.git*"

          echo "‚úÖ Lambda deployment package created successfully"
          echo "üìä Package contents:"
          unzip -l lambda-deployment.zip

      - name: Deploy Lambda function
        run: |
          # Use dynamic function name from environment detection
          FUNCTION_NAME="${{ needs.detect-environment.outputs.function_name }}"

          echo "üîÑ Updating Lambda function: $FUNCTION_NAME"

          # Wait for Lambda to be ready
          check_lambda_ready() {
            local status=$(aws lambda get-function --function-name $FUNCTION_NAME --query 'Configuration.State' --output text 2>/dev/null)
            echo "Lambda status: $status"
            [[ "$status" == "Active" ]]
          }

          # Wait for Lambda to be ready before updating
          echo "‚è≥ Waiting for Lambda to be ready..."
          for i in {1..30}; do
            if check_lambda_ready; then
              echo "‚úÖ Lambda is ready for update"
              break
            fi
            echo "‚è≥ Waiting... (attempt $i/30)"
            sleep 10
          done

          # Update Lambda with retry logic
          update_lambda() {
            local max_attempts=5
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              echo "üîÑ Attempting Lambda update (attempt $attempt/$max_attempts)..."
              
              if aws lambda update-function-code --function-name $FUNCTION_NAME --zip-file fileb://lambda-deployment.zip; then
                echo "‚úÖ Lambda update successful"
                return 0
              else
                echo "‚ùå Lambda update failed (attempt $attempt/$max_attempts)"
                
                if [ $attempt -lt $max_attempts ]; then
                  echo "‚è≥ Waiting before retry..."
                  sleep $((attempt * 10))
                fi
                
                attempt=$((attempt + 1))
              fi
            done
            
            echo "‚ùå All Lambda update attempts failed"
            return 1
          }

          update_lambda

      - name: Verify Lambda permissions after deployment
        run: |
          # Use dynamic function name from environment detection
          FUNCTION_NAME="${{ needs.detect-environment.outputs.function_name }}"

          echo "üîç Verifying Lambda permissions are managed by Terraform..."

          # Check if Lambda has the correct API Gateway permission
          if aws lambda get-policy --function-name "$FUNCTION_NAME" --query 'Policy' --output text 2>/dev/null; then
            echo "‚úÖ Lambda has permission policy"
            
            # Check if the permission matches what Terraform should create
            POLICY_JSON=$(aws lambda get-policy --function-name "$FUNCTION_NAME" --query 'Policy' --output text)
            
            if echo "$POLICY_JSON" | grep -q "AllowExecutionFromAPIGateway"; then
              echo "‚úÖ API Gateway permission found"
            else
              echo "‚ö†Ô∏è API Gateway permission missing - this may cause health check failures"
            fi
            
            # Show current permissions for verification
            echo "üìã Current Lambda permissions:"
            echo "$POLICY_JSON" | jq . 2>/dev/null || echo "$POLICY_JSON"
            
          else
            echo "‚ö†Ô∏è No permission policy found on Lambda function"
            echo "This will likely cause API Gateway integration errors"
          fi

      - name: Wait for Lambda update
        run: |
          # Use dynamic function name from environment detection
          FUNCTION_NAME="${{ needs.detect-environment.outputs.function_name }}"
          aws lambda wait function-updated --function-name $FUNCTION_NAME

  # =================================
  # Health Check
  # =================================
  health-check:
    name: Health Check
    runs-on: ubuntu-latest
    needs: [detect-environment, deploy-frontend, deploy-backend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get API Gateway URL
        id: api-url
        run: |
          # Use dynamic environment variables
          ENVIRONMENT="${{ needs.detect-environment.outputs.environment }}"
          MAIN_ENV="${{ needs.detect-environment.outputs.main_env }}"
          PROJECT_NAME="dpp"

          # Primary expected API Gateway name (matches module configuration)
          PRIMARY_API_NAME="${MAIN_ENV}-${ENVIRONMENT}-${PROJECT_NAME}-api"
          # Alternative naming patterns to check
          ALT_API_NAME1="${{ needs.detect-environment.outputs.function_name }}"
          ALT_API_NAME2="${ENVIRONMENT}-${PROJECT_NAME}-api"

          echo "üîç Looking for API Gateway with multiple naming patterns:"
          echo "  Primary: $PRIMARY_API_NAME"
          echo "  Alternative 1: $ALT_API_NAME1"
          echo "  Alternative 2: $ALT_API_NAME2"

          # Function to find API by name and validate it exists
          find_and_validate_api() {
            local api_name="$1"
            echo "üîç Checking for API Gateway: $api_name" >&2
            
            # Get all API IDs with this name, sorted by creation date (newest first)
            local potential_api_ids=$(aws apigatewayv2 get-apis \
              --query "Items[?Name=='$api_name'] | sort_by(@, &CreatedDate) | reverse(@) | [*].ApiId" \
              --output text | tr -s '[:space:]' '\n')
            
            if [ -z "$potential_api_ids" ] || [ "$potential_api_ids" = "None" ]; then
              echo "‚ùå No API found with name: $api_name" >&2
              return 1
            fi
            
            echo "üîé Found $(echo "$potential_api_ids" | wc -l) API(s) with name '$api_name'" >&2
            
            # Try each API ID (newest first) until we find a valid one
            local line_number=1
            while IFS= read -r potential_api_id; do
              # Clean the API ID
              potential_api_id=$(echo "$potential_api_id" | tr -d '[:space:]')
              
              if [ -n "$potential_api_id" ] && [ "$potential_api_id" != "None" ]; then
                echo "üîé Testing API ID #$line_number: $potential_api_id" >&2
                
                # Validate the API actually exists by trying to get its details
                if aws apigatewayv2 get-api --api-id "$potential_api_id" >/dev/null 2>&1; then
                  echo "‚úÖ Validated API Gateway '$api_name' with ID: $potential_api_id" >&2
                  echo "$potential_api_id"  # This is the only output to stdout
                  return 0
                else
                  echo "‚ùå API ID $potential_api_id is invalid or inaccessible" >&2
                fi
              fi
              line_number=$((line_number + 1))
            done <<< "$potential_api_ids"
            
            echo "‚ùå No valid API IDs found for name: $api_name" >&2
            return 1
          }

          # Try to find and validate API Gateway with different naming patterns
          API_ID=""
          API_NAME_FOUND=""
          for api_name in "$PRIMARY_API_NAME" "$ALT_API_NAME1" "$ALT_API_NAME2"; do
            # Call function and capture return code
            if temp_api_id=$(find_and_validate_api "$api_name"); then
              # The function only outputs the API ID to stdout on success
              API_ID="$temp_api_id"
              API_NAME_FOUND="$api_name"
              echo "‚úÖ Successfully found and validated API Gateway: $api_name ($API_ID)"
              break
            fi
          done

          # If still not found, list all APIs for debugging but don't use fuzzy search
          if [ -z "$API_ID" ] || [ "$API_ID" = "None" ] || [ "$API_ID" = "" ]; then
            echo "‚ùå No valid API Gateway found with expected names"
            echo ""
            echo "üîç Available APIs in region ${{ env.AWS_REGION }}:"
            aws apigatewayv2 get-apis --query 'Items[*].{Name:Name,Id:ApiId,Protocol:ProtocolType,CreatedDate:CreatedDate}' --output table
            
            # Check for duplicate API names
            echo ""
            echo "üîç Checking for duplicate API Gateway names..."
            DUPLICATE_APIS=$(aws apigatewayv2 get-apis \
              --query 'Items[*].Name' --output text | sort | uniq -d)
            
            if [ -n "$DUPLICATE_APIS" ]; then
              echo "‚ö†Ô∏è Found duplicate API Gateway names:"
              echo "$DUPLICATE_APIS"
              echo ""
              echo "üßπ Cleanup recommendation:"
              echo "You have multiple API Gateways with the same name, which can cause issues."
              echo "Consider deleting the older/unused ones:"
              echo ""
              for dup_name in $DUPLICATE_APIS; do
                echo "APIs with name '$dup_name':"
                aws apigatewayv2 get-apis \
                  --query "Items[?Name=='$dup_name'].{Id:ApiId,Created:CreatedDate}" \
                  --output table
                echo "Suggested cleanup (delete older APIs):"
                OLDER_IDS=$(aws apigatewayv2 get-apis \
                  --query "Items[?Name=='$dup_name'] | sort_by(@, &CreatedDate) | [:-1] | [*].ApiId" \
                  --output text)
                for old_id in $OLDER_IDS; do
                  echo "  aws apigatewayv2 delete-api --api-id $old_id"
                done
                echo ""
              done
            fi
            
            echo ""
            echo "üîß Troubleshooting steps:"
            echo "1. Check if Terraform deployment completed successfully"
            echo "2. Verify API Gateway module was applied without errors"
            echo "3. Look for API Gateway creation logs in deployment output"
            echo "4. Expected API name should be: $PRIMARY_API_NAME"
            if [ -n "$DUPLICATE_APIS" ]; then
              echo "5. Clean up duplicate API Gateways using the commands above"
            fi
            echo ""
            echo "‚ùå Cannot proceed with health check - no valid API Gateway found"
            exit 1
          fi

          # Clean and validate the API ID format
          API_ID=$(echo "$API_ID" | tr -d '[:space:]' | head -n 1)

          # Validate API ID format (should be alphanumeric, roughly 10 characters)
          if ! echo "$API_ID" | grep -E '^[a-z0-9]{8,15}$' >/dev/null; then
            echo "‚ùå Invalid API ID format: '$API_ID'"
            echo "üîß API ID should be alphanumeric string, got: $(echo "$API_ID" | cat -v)"
            echo "This suggests an issue with the API lookup logic."
            exit 1
          fi

          echo "‚úÖ Using clean API ID: $API_ID (found via: $API_NAME_FOUND)"

          # Double-check API exists and get additional details
          echo "üîç Validating final API Gateway configuration..."
          if ! aws apigatewayv2 get-api --api-id "$API_ID" >/dev/null 2>&1; then
            echo "‚ùå Final validation failed - API Gateway $API_ID does not exist"
            exit 1
          fi

          # Check if API has stages (required for health check)
          STAGES=$(aws apigatewayv2 get-stages --api-id "$API_ID" --query 'Items[*].StageName' --output text 2>/dev/null)
          if [ -z "$STAGES" ] || [ "$STAGES" = "None" ]; then
            echo "‚ùå API Gateway $API_ID has no stages configured"
            echo "üîß This indicates incomplete deployment - API Gateway needs at least one stage"
            exit 1
          else
            echo "‚úÖ API Gateway has stages: $STAGES"
          fi

          # Check if API has routes (required for /health endpoint)
          ROUTES=$(aws apigatewayv2 get-routes --api-id "$API_ID" --query 'Items[*].RouteKey' --output text 2>/dev/null)
          if [ -z "$ROUTES" ] || [ "$ROUTES" = "None" ]; then
            echo "‚ùå API Gateway $API_ID has no routes configured"
            echo "üîß This indicates incomplete deployment - API Gateway needs routes for /health endpoint"
            exit 1
          else
            echo "‚úÖ API Gateway has routes configured"
          fi

          # Construct the API URL using the validated stage
          # Use the first stage found (typically 'v1' based on your configuration)
          FIRST_STAGE=$(echo "$STAGES" | awk '{print $1}')
          API_URL="https://${API_ID}.execute-api.${{ env.AWS_REGION }}.amazonaws.com/${FIRST_STAGE}"

          echo "‚úÖ Using validated API Gateway: $API_ID"
          echo "üåê API URL: $API_URL"

          # Final DNS pre-check to verify the hostname resolves
          echo "üîç Pre-checking DNS resolution..."
          API_HOSTNAME="${API_ID}.execute-api.${{ env.AWS_REGION }}.amazonaws.com"
          if nslookup "$API_HOSTNAME" >/dev/null 2>&1; then
            echo "‚úÖ DNS resolution successful for $API_HOSTNAME"
          else
            echo "‚ö†Ô∏è DNS resolution issue detected for $API_HOSTNAME"
            echo "üîß This might be due to recent API Gateway creation - DNS propagation can take a few minutes"
            echo "Will proceed with health check but may need retries..."
          fi

          # Set the output
          echo "api_url=${API_URL}" >> $GITHUB_OUTPUT

      - name: Test API health endpoint
        run: |
          # Use the dynamically generated API URL from the previous step
          API_URL="${{ steps.api-url.outputs.api_url }}/health"

          # Clean the URL to remove any whitespace or special characters
          API_URL=$(echo "$API_URL" | tr -d '[:space:]')

          echo "Testing API health endpoint: $API_URL"
          echo "URL length: ${#API_URL} characters"

          # Function to gather AWS logs for debugging
          gather_aws_logs() {
            local lambda_name="$1"
            local api_id="$2"
            
            echo "üîç Gathering AWS logs for debugging..."
            
            # Get Lambda function logs from CloudWatch
            local lambda_log_group="/aws/lambda/$lambda_name"
            echo "üìã Checking Lambda logs in: $lambda_log_group"
            
            if aws logs describe-log-groups --log-group-name-prefix "$lambda_log_group" --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q "$lambda_log_group"; then
              echo "üìÑ Recent Lambda log events:"
              aws logs filter-log-events \
                --log-group-name "$lambda_log_group" \
                --start-time $(($(date +%s) * 1000 - 600000)) \
                --query 'events[*].[timestamp,message]' \
                --output table \
                --max-items 20 || echo "‚ö†Ô∏è Could not retrieve Lambda logs"
            else
              echo "‚ö†Ô∏è Lambda log group not found: $lambda_log_group"
            fi
            
            # Get API Gateway logs
            local api_log_group="/aws/apigateway/dev-dev01-dpp"
            echo "üìã Checking API Gateway logs in: $api_log_group"
            
            if aws logs describe-log-groups --log-group-name-prefix "$api_log_group" --query 'logGroups[0].logGroupName' --output text 2>/dev/null | grep -q "$api_log_group"; then
              echo "üìÑ Recent API Gateway log events:"
              aws logs filter-log-events \
                --log-group-name "$api_log_group" \
                --start-time $(($(date +%s) * 1000 - 600000)) \
                --query 'events[*].[timestamp,message]' \
                --output table \
                --max-items 20 || echo "‚ö†Ô∏è Could not retrieve API Gateway logs"
            else
              echo "‚ö†Ô∏è API Gateway log group not found: $api_log_group"
            fi
            
            # Check Lambda function status
            echo "üîç Lambda function status:"
            aws lambda get-function --function-name "$lambda_name" \
              --query '{State:Configuration.State,LastModified:Configuration.LastModified,Runtime:Configuration.Runtime,Handler:Configuration.Handler}' \
              --output table || echo "‚ö†Ô∏è Could not get Lambda function details"
            
            # Check API Gateway status
            if [ -n "$api_id" ]; then
              echo "üîç API Gateway status:"
              aws apigatewayv2 get-api --api-id "$api_id" \
                --query '{Name:Name,ProtocolType:ProtocolType,RouteSelectionExpression:RouteSelectionExpression,CreatedDate:CreatedDate}' \
                --output table || echo "‚ö†Ô∏è Could not get API Gateway details"
              
              echo "üîç API Gateway routes:"
              aws apigatewayv2 get-routes --api-id "$api_id" \
                --query 'Items[*].{RouteKey:RouteKey,Target:Target}' \
                --output table || echo "‚ö†Ô∏è Could not get API Gateway routes"
              
              echo "üîç API Gateway stages:"
              aws apigatewayv2 get-stages --api-id "$api_id" \
                --query 'Items[*].{StageName:StageName,DeploymentId:DeploymentId,CreatedDate:CreatedDate}' \
                --output table || echo "‚ö†Ô∏è Could not get API Gateway stages"
            fi
          }

          # Function to test health endpoint with detailed logging
          test_health_endpoint() {
            local url="$1"
            local attempt="$2"
            
            echo "üîÑ Health check attempt $attempt/5..."
            echo "üì° Testing URL: $url"
            
            # Test with curl and capture HTTP status code and response body separately
            local http_code response_body curl_exit_code response
            
            echo "üîç Performing detailed curl test..."
            
            # Use curl with reliable HTTP status code extraction
            response=$(curl -s -w "HTTPSTATUS:%{http_code}" \
              --max-time 30 \
              --connect-timeout 10 \
              --retry 0 \
              -H "Accept: application/json" \
              -H "User-Agent: GitHub-Actions-Health-Check" \
              "$url" 2>&1)
            
            curl_exit_code=$?
            
            echo "üìä Curl exit code: $curl_exit_code"
            
            # Parse response reliably - separate body and HTTP status
            response_body=$(echo "$response" | sed -e 's/HTTPSTATUS\:.*//g')
            http_code=$(echo "$response" | tr -d '\n' | sed -e 's/.*HTTPSTATUS://')
            
            echo "üìã Response body:"
            echo "$response_body"
            echo "üìä HTTP Status Code: $http_code"
            
            # Analyze the response
            case $curl_exit_code in
              0)
                if [ "$http_code" = "200" ]; then
                  echo "‚úÖ Health check successful! HTTP $http_code"
                  echo "üìã Health response: $response_body"
                  return 0
                else
                  echo "‚ùå Health check failed with HTTP $http_code"
                  echo "üìã Response body: $response_body"
                  return 1
                fi
                ;;
              6)
                echo "‚ùå Curl exit code 6: Could not resolve host"
                echo "üîç DNS resolution issue detected"
                # Test DNS resolution
                echo "üß™ Testing DNS resolution:"
                local hostname=$(echo "$url" | cut -d'/' -f3)
                nslookup "$hostname" || echo "‚ö†Ô∏è DNS lookup failed"
                dig +short "$hostname" || echo "‚ö†Ô∏è Dig lookup failed"
                return 6
                ;;
              7)
                echo "‚ùå Curl exit code 7: Failed to connect to host"
                echo "üîç Connection issue detected"
                return 7
                ;;
              28)
                echo "‚ùå Curl exit code 28: Connection timeout"
                echo "üîç Timeout issue detected"
                return 28
                ;;
              *)
                echo "‚ùå Curl exit code $curl_exit_code: $(curl --help | grep "Exit code $curl_exit_code" || echo "Unknown error")"
                return $curl_exit_code
                ;;
            esac
          }

          # Extract Lambda function name and API ID for log gathering
          LAMBDA_NAME=$(echo "${{ steps.api-url.outputs.api_url }}" | grep -o 'https://[^.]*' | cut -d'/' -f3)
          API_ID=$(echo "${{ steps.api-url.outputs.api_url }}" | cut -d'.' -f1 | cut -d'/' -f3)

          echo "üîç Extracted details:"
          echo "  - API ID: $API_ID"
          echo "  - Lambda function: ${{ needs.detect-environment.outputs.function_name }}"

          # Perform health check with retries
          max_attempts=5
          attempt=1
          success=false

          while [ $attempt -le $max_attempts ] && [ "$success" = false ]; do
            if test_health_endpoint "$API_URL" "$attempt"; then
              success=true
              echo "üéâ Health check passed on attempt $attempt!"
              break
            else
              health_exit_code=$?
              echo "‚ö†Ô∏è Attempt $attempt failed with exit code $health_exit_code"
              
              if [ $attempt -eq $max_attempts ]; then
                echo "‚ùå All health check attempts failed!"
                echo "üîç Gathering detailed AWS logs for debugging..."
                gather_aws_logs "${{ needs.detect-environment.outputs.function_name }}" "$API_ID"
                
                echo "üîß Troubleshooting suggestions:"
                echo "1. Check if Lambda function is properly deployed and active"
                echo "2. Verify API Gateway routes and integrations are configured"
                echo "3. Check security groups and network connectivity"
                echo "4. Review CloudWatch logs for errors"
                echo "5. Verify the health endpoint implementation in your Lambda function"
                
                exit $health_exit_code
              else
                echo "‚è≥ Waiting 30 seconds before retry..."
                sleep 30
              fi
            fi
            
            attempt=$((attempt + 1))
          done

          if [ "$success" = true ]; then
            echo "‚úÖ API health check completed successfully!"
          fi
