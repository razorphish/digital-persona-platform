name: Deploy Serverless Architecture

on:
  push:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  pull_request:
    branches:
      - main
      - "dev[0-9][0-9]"
      - "qa[0-9][0-9]"
      - "staging[0-9][0-9]"
      - "hotfix[0-9][0-9]"
  workflow_dispatch:
    inputs:
      force_deploy:
        description: "Force deployment even if tests fail"
        required: false
        default: false
        type: boolean
      skip_tests:
        description: "Skip test execution for emergency deployments"
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  security-events: write
  actions: read
  contents: read

env:
  AWS_REGION: us-west-1
  NODE_VERSION: 20
  # Remove hardcoded DOMAIN - will be determined dynamically

# Prevent multiple runs from conflicting
concurrency:
  group: serverless-deployment-${{ github.ref_name }}
  cancel-in-progress: true

jobs:
  # ===========================================
  # Environment Detection & Setup
  # ===========================================
  detect-environment:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      main_env: ${{ steps.env.outputs.main_env }}
      should_deploy: ${{ steps.env.outputs.should_deploy }}
      is_numbered_env: ${{ steps.env.outputs.is_numbered_env }}
      function_name: ${{ steps.env.outputs.function_name }}
      s3_bucket: ${{ steps.env.outputs.s3_bucket }}
      api_url: ${{ steps.env.outputs.api_url }}
      domain_name: ${{ steps.env.outputs.domain_name }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Determine Environment and Resources
        id: env
        run: |
          # Determine environment based on branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            ENVIRONMENT="prod"
            MAIN_ENV="prod"
            SHOULD_DEPLOY="false"  # Main branch requires manual deployment
            IS_NUMBERED_ENV="false"
          elif [[ "${{ github.ref_name }}" =~ ^dev[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="dev"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^qa[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="qa"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^staging[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="staging"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          elif [[ "${{ github.ref_name }}" =~ ^hotfix[0-9][0-9]$ ]]; then
            ENVIRONMENT="${{ github.ref_name }}"
            MAIN_ENV="hotfix"
            SHOULD_DEPLOY="true"
            IS_NUMBERED_ENV="true"
          else
            echo "❌ Invalid branch name: ${{ github.ref_name }}"
            echo "Valid branches: main, dev01-dev99, qa01-qa99, staging01-staging99, hotfix01-hotfix99"
            exit 1
          fi

          # Generate dynamic resource names
          FUNCTION_NAME="$MAIN_ENV-$ENVIRONMENT-dpp-api"
          S3_BUCKET="$MAIN_ENV-$ENVIRONMENT-dpp-website"

          # Generate API URL dynamically based on environment pattern
          DOMAIN_NAME="${ENVIRONMENT}.hibiji.com"

          # Determine HIBIJI_API_URL based on existing resources or prediction
          API_URL="https://${ENVIRONMENT}-api.hibiji.com/v1"

          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "main_env=$MAIN_ENV" >> $GITHUB_OUTPUT
          echo "should_deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT
          echo "is_numbered_env=$IS_NUMBERED_ENV" >> $GITHUB_OUTPUT
          echo "function_name=$FUNCTION_NAME" >> $GITHUB_OUTPUT
          echo "s3_bucket=$S3_BUCKET" >> $GITHUB_OUTPUT
          echo "api_url=$API_URL" >> $GITHUB_OUTPUT
          echo "domain_name=$DOMAIN_NAME" >> $GITHUB_OUTPUT

          echo "🎯 Environment: $ENVIRONMENT"
          echo "🏗️ Main Environment: $MAIN_ENV"
          echo "🚀 Should Deploy: $SHOULD_DEPLOY"
          echo "🔢 Is Numbered Environment: $IS_NUMBERED_ENV"
          echo "⚡ Function Name: $FUNCTION_NAME"
          echo "🪣 S3 Bucket: $S3_BUCKET"
          echo "🌐 API URL: $API_URL"
          echo "🏡 Domain Name: $DOMAIN_NAME"

  # ===========================================
  # Dependency Scanning (Security)
  # ===========================================
  dependency-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    continue-on-error: true
    if: github.event.inputs.skip_tests != 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs"
          format: "sarif"
          output: "trivy-results.sarif"

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: "trivy-results.sarif"

  # ===========================================
  # Build Phase
  # ===========================================
  build-backend:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [detect-environment]
    outputs:
      backend-hash: ${{ steps.hash.outputs.backend-hash }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"
          cache-dependency-path: "package-lock.json"

      - name: Install dependencies
        run: npm ci

      - name: Build workspace packages
        run: |
          echo "🔧 Building workspace packages..."
          npm run build --workspace=@digital-persona/database
          npm run build --workspace=@digital-persona/shared

      - name: Build backend for Lambda
        working-directory: apps/server
        run: |
          echo "📦 Building backend for Lambda deployment..."
          npm run build:lambda

      - name: Generate build hash
        id: hash
        run: |
          HASH=$(echo "${{ github.sha }}-${{ needs.detect-environment.outputs.environment }}" | sha256sum | cut -d' ' -f1 | head -c 8)
          echo "backend-hash=$HASH" >> $GITHUB_OUTPUT
          echo "📋 Build hash: $HASH"

      - name: Upload backend artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backend-${{ needs.detect-environment.outputs.environment }}-${{ steps.hash.outputs.backend-hash }}
          path: |
            apps/server/lambda-dist/index.js
            apps/server/lambda-dist/package.json

  build-frontend:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [detect-environment]
    outputs:
      frontend-hash: ${{ steps.hash.outputs.frontend-hash }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"
          cache-dependency-path: "package-lock.json"

      - name: Install dependencies
        run: npm ci

      - name: Build workspace packages
        run: |
          echo "🔧 Building workspace packages..."
          npm run build --workspace=@digital-persona/database
          npm run build --workspace=@digital-persona/shared

      - name: Build frontend for static hosting
        working-directory: apps/web
        env:
          NEXT_PUBLIC_API_URL: ${{ needs.detect-environment.outputs.api_url }}
          NEXT_BUILD_EXPORT: "true"
        run: |
          echo "📦 Building frontend for static hosting..."
          echo "🌐 API URL: $NEXT_PUBLIC_API_URL"
          echo "📦 Export mode: Static export for S3"
          npm run build

      - name: Generate build hash
        id: hash
        run: |
          HASH=$(echo "${{ github.sha }}-${{ needs.detect-environment.outputs.environment }}" | sha256sum | cut -d' ' -f1 | head -c 8)
          echo "frontend-hash=$HASH" >> $GITHUB_OUTPUT
          echo "📋 Build hash: $HASH"

      - name: Upload frontend artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-${{ needs.detect-environment.outputs.environment }}-${{ steps.hash.outputs.frontend-hash }}
          path: apps/web/out/

  # ===========================================
  # Infrastructure Deployment
  # ===========================================
  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    needs: [detect-environment, dependency-scan]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}
    timeout-minutes: 45
    environment: ${{ needs.detect-environment.outputs.environment }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"

      - name: Cache Terraform
        uses: actions/cache@v4
        with:
          path: |
            terraform/environments/${{ needs.detect-environment.outputs.main_env }}/.terraform
            terraform/environments/${{ needs.detect-environment.outputs.main_env }}/.terraform.lock.hcl
          key: ${{ runner.os }}-terraform-serverless-${{ needs.detect-environment.outputs.main_env }}-${{ hashFiles('terraform/**/*.tf') }}

      - name: Terraform Init and Plan
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        env:
          ENVIRONMENT: ${{ needs.detect-environment.outputs.environment }}
          MAIN_ENV: ${{ needs.detect-environment.outputs.main_env }}
          PROJECT_NAME: "dpp"
        run: |
          echo "🚀 Step 1: Terraform Initialization..."
          terraform init

          echo "🎯 Step 2: Variables Configuration..."
          echo "Environment: $ENVIRONMENT"
          echo "Main Environment: $MAIN_ENV"

          # Create tfvars file
          cat > environment.auto.tfvars << EOF
          environment = "$MAIN_ENV"
          sub_environment = "$ENVIRONMENT"
          project_name = "$PROJECT_NAME"
          domain_name = "hibiji.com"
          aws_region = "${{ env.AWS_REGION }}"
          alert_emails = ["alerts@maras.co"]
          EOF

          echo "📋 Step 3: Terraform Planning..."
          terraform plan -var-file="environment.auto.tfvars" -out=tfplan

      - name: Import Existing Resources
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        env:
          ENVIRONMENT: ${{ needs.detect-environment.outputs.environment }}
          MAIN_ENV: ${{ needs.detect-environment.outputs.main_env }}
          PROJECT_NAME: "dpp"
        run: |
          echo "📥 Step 3: Importing existing resources into Terraform state..."

          # Helper function for safe imports
          safe_import() {
            local resource_address="$1"
            local resource_id="$2"
            local resource_type="$3"
            local description="$4"
            
            echo "🔍 Checking if $description exists in state..."
            if ! terraform state show "$resource_address" >/dev/null 2>&1; then
              echo "📥 Importing $description: $resource_id"
              if terraform import "$resource_address" "$resource_id" 2>/dev/null; then
                echo "✅ Successfully imported $description"
              else
                echo "⚠️ Failed to import $description (may not exist or lack permissions)"
              fi
            else
              echo "✅ $description already in state"
            fi
          }

          # Import Route53 hosted zone (shared across environments)
          HOSTED_ZONE_ID=$(aws route53 list-hosted-zones --query 'HostedZones[?Name==`hibiji.com.`].Id' --output text | sed 's|/hostedzone/||')
          if [ ! -z "$HOSTED_ZONE_ID" ] && [ "$HOSTED_ZONE_ID" != "None" ]; then
            safe_import "data.aws_route53_zone.main" "$HOSTED_ZONE_ID" "hosted_zone" "Route53 hosted zone"
          fi

          echo "✅ Resource import completed"

      - name: Apply Terraform Configuration
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        env:
          ENVIRONMENT: ${{ needs.detect-environment.outputs.environment }}
          MAIN_ENV: ${{ needs.detect-environment.outputs.main_env }}
          PROJECT_NAME: "dpp"
        run: |
          echo "🏗️ Step 4: Applying Terraform configuration..."

          # Get plan exit code to check if changes are needed
          PLAN_EXIT_CODE=0
          terraform plan -var-file="environment.auto.tfvars" -detailed-exitcode -out=tfplan || PLAN_EXIT_CODE=$?

          if [ $PLAN_EXIT_CODE -eq 2 ]; then
            echo "🚀 Step 4: Applying Terraform configuration..."

            # First attempt: Full apply with timeout
            echo "🎯 Attempt 1: Full Terraform apply..."
            if timeout 1800 terraform apply -auto-approve -lock-timeout=300s tfplan; then
              echo "✅ Full Terraform apply completed successfully!"
            else
              echo "⚠️ Full apply failed, trying targeted deployment..."
              
              # Second attempt: Core infrastructure first
              echo "🏗️ Attempt 2: Core infrastructure deployment..."
              
              # Apply VPC and networking first
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_vpc.main \
                -target=aws_subnet.private \
                -target=aws_internet_gateway.main \
                -target=aws_security_group.database \
                -target=aws_security_group.lambda || echo "⚠️ VPC deployment issues"
              
              # Apply secrets and database
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_secretsmanager_secret.jwt_secret \
                -target=aws_secretsmanager_secret.database_password \
                -target=aws_secretsmanager_secret_version.jwt_secret \
                -target=aws_secretsmanager_secret_version.database_password \
                -target=aws_db_subnet_group.database \
                -target=aws_rds_cluster.database \
                -target=aws_rds_cluster_instance.database || echo "⚠️ Database deployment issues"
              
              # Apply S3 buckets
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_s3_bucket.uploads \
                -target=module.s3_website \
                -target=module.lambda_backend.aws_s3_bucket.lambda_deployments || echo "⚠️ S3 deployment issues"
              
              # Apply serverless components
              terraform apply -auto-approve -lock-timeout=300s \
                -target=module.lambda_backend \
                -target=module.api_gateway || echo "⚠️ Serverless deployment issues"
              
              # Apply DNS records last
              terraform apply -auto-approve -lock-timeout=300s \
                -target=aws_route53_record.website \
                -target=aws_route53_record.api || echo "⚠️ DNS deployment issues"
            fi
          else
            echo "✅ No infrastructure changes needed (plan exit code: $PLAN_EXIT_CODE)"
          fi

      - name: Verify Infrastructure
        working-directory: terraform/environments/${{ needs.detect-environment.outputs.main_env }}
        run: |
          echo "🔍 Step 5: Verifying infrastructure deployment..."

          # Get outputs
          terraform output -json > outputs.json

          echo "📋 Terraform Outputs:"
          cat outputs.json | jq .

          # Verify key resources exist
          echo "🔍 Verifying key resources..."

          # Check Lambda function
          FUNCTION_NAME=$(terraform output -raw lambda_function_name 2>/dev/null || echo "")
          if [ ! -z "$FUNCTION_NAME" ]; then
            echo "✅ Lambda function: $FUNCTION_NAME"
          fi

          # Check S3 website bucket
          WEBSITE_BUCKET=$(terraform output -raw website_bucket_name 2>/dev/null || echo "")
          if [ ! -z "$WEBSITE_BUCKET" ]; then
            echo "✅ Website S3 bucket: $WEBSITE_BUCKET"
          fi

          # Check API Gateway URL
          API_URL=$(terraform output -raw api_url 2>/dev/null || echo "")
          if [ ! -z "$API_URL" ]; then
            echo "✅ API Gateway URL: $API_URL"
          fi

      - name: Upload Terraform outputs
        uses: actions/upload-artifact@v4
        with:
          name: terraform-outputs-${{ needs.detect-environment.outputs.environment }}
          path: terraform/environments/${{ needs.detect-environment.outputs.main_env }}/outputs.json

  # ===========================================
  # Application Deployment
  # ===========================================
  deploy-backend:
    name: Deploy Backend
    runs-on: ubuntu-latest
    needs: [detect-environment, deploy-infrastructure, build-backend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download backend artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-${{ needs.detect-environment.outputs.environment }}-${{ needs.build-backend.outputs.backend-hash }}

      - name: Locate and prepare Lambda files
        run: |
          echo "📦 Locating Lambda bundle files after artifact download..."
          echo "📁 Current directory contents:"
          ls -la

          # Find index.js location and move to current directory if needed
          INDEX_JS_PATH=$(find . -name "index.js" -type f | head -1)
          PACKAGE_JSON_PATH=$(find . -name "package.json" -path "*/lambda-dist/*" -type f | head -1)

          if [ -z "$INDEX_JS_PATH" ]; then
            echo "❌ index.js not found anywhere"
            echo "📁 Available files:"
            find . -name "*.js" -o -name "*.json" | head -10
            exit 1
          fi

          echo "📍 Found index.js at: $INDEX_JS_PATH"

          # Move files to current directory if they're in subdirectories
          if [ "$INDEX_JS_PATH" != "./index.js" ]; then
            echo "📦 Moving Lambda files to current directory..."
            cp "$INDEX_JS_PATH" ./index.js
            
            if [ -n "$PACKAGE_JSON_PATH" ]; then
              echo "📍 Found package.json at: $PACKAGE_JSON_PATH"
              cp "$PACKAGE_JSON_PATH" ./package.json
            fi
          fi

          echo "✅ Lambda files prepared:"
          ls -la index.js package.json

      - name: Create Lambda deployment package
        run: |
          echo "📦 Creating Lambda deployment package from bundled output..."

          # Create deployment zip from current directory (which contains the bundled output)
          echo "📦 Creating deployment zip from bundled files..."
          zip -r lambda-deployment.zip . -x "*.DS_Store*" "*.git*"

          echo "✅ Lambda deployment package created successfully"
          echo "📊 Package contents:"
          unzip -l lambda-deployment.zip

      - name: Deploy Lambda function
        run: |
          # Use dynamic function name from environment detection
          FUNCTION_NAME="${{ needs.detect-environment.outputs.function_name }}"

          echo "🔄 Updating Lambda function: $FUNCTION_NAME"

          # Wait for Lambda to be ready
          check_lambda_ready() {
            local status=$(aws lambda get-function --function-name $FUNCTION_NAME --query 'Configuration.State' --output text 2>/dev/null)
            echo "Lambda status: $status"
            [[ "$status" == "Active" ]]
          }

          # Wait for Lambda to be ready before updating
          echo "⏳ Waiting for Lambda to be ready..."
          for i in {1..30}; do
            if check_lambda_ready; then
              echo "✅ Lambda is ready for update"
              break
            fi
            echo "⏳ Waiting... (attempt $i/30)"
            sleep 10
          done

          # Update Lambda with retry logic
          update_lambda() {
            local max_attempts=5
            local attempt=1
            
            while [ $attempt -le $max_attempts ]; do
              echo "🔄 Attempting Lambda update (attempt $attempt/$max_attempts)..."
              
              if aws lambda update-function-code --function-name $FUNCTION_NAME --zip-file fileb://lambda-deployment.zip; then
                echo "✅ Lambda update successful"
                return 0
              else
                echo "❌ Lambda update failed (attempt $attempt/$max_attempts)"
                
                if [ $attempt -lt $max_attempts ]; then
                  echo "⏳ Waiting before retry..."
                  sleep $((attempt * 10))
                fi
                
                attempt=$((attempt + 1))
              fi
            done
            
            echo "❌ All Lambda update attempts failed"
            return 1
          }

          update_lambda

      - name: Verify Lambda permissions after deployment
        run: |
          FUNCTION_NAME="${{ needs.detect-environment.outputs.function_name }}"

          echo "🔍 Verifying Lambda function configuration..."

          # Get function configuration
          aws lambda get-function --function-name $FUNCTION_NAME --query 'Configuration.{Runtime:Runtime,Timeout:Timeout,MemorySize:MemorySize,State:State}' --output table

          # Test Lambda function with proper API Gateway event format
          echo "🧪 Testing Lambda function..."
          echo '{
            "httpMethod": "GET",
            "path": "/health",
            "pathParameters": null,
            "queryStringParameters": null,
            "headers": {
              "Accept": "application/json",
              "Content-Type": "application/json",
              "User-Agent": "AWS-Lambda-Test/1.0"
            },
            "multiValueHeaders": {},
            "requestContext": {
              "requestId": "test-request-id",
              "stage": "test",
              "httpMethod": "GET",
              "path": "/health"
            },
            "body": null,
            "isBase64Encoded": false
          }' > test-payload.json
          aws lambda invoke --function-name $FUNCTION_NAME --payload file://test-payload.json --cli-binary-format raw-in-base64-out response.json

          if [ -f response.json ]; then
            echo "📋 Lambda response:"
            cat response.json
          fi

  deploy-frontend:
    name: Deploy Frontend
    runs-on: ubuntu-latest
    needs: [detect-environment, deploy-infrastructure, build-frontend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download frontend artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-${{ needs.detect-environment.outputs.environment }}-${{ needs.build-frontend.outputs.frontend-hash }}

      - name: Download Terraform outputs
        uses: actions/download-artifact@v4
        with:
          name: terraform-outputs-${{ needs.detect-environment.outputs.environment }}

      - name: Deploy to S3
        run: |
          # Extract S3 bucket name from Terraform outputs
          if [ -f outputs.json ]; then
            S3_BUCKET=$(cat outputs.json | jq -r '.website_bucket_name.value // empty')
          fi

          # Fallback to detected bucket name
          if [ -z "$S3_BUCKET" ]; then
            S3_BUCKET="${{ needs.detect-environment.outputs.s3_bucket }}"
          fi

          echo "📤 Deploying frontend to S3 bucket: $S3_BUCKET"
          echo "📁 Current directory contents:"
          ls -la

          # Sync frontend files to S3
          echo "🔄 Syncing files to S3..."
          if [ -f "index.html" ]; then
            echo "✅ Frontend build output found (files extracted to current directory)"
            aws s3 sync . s3://$S3_BUCKET/ --delete --cache-control "max-age=31536000" --exclude "*.html" --exclude "*.json" --exclude "outputs.json"
            aws s3 sync . s3://$S3_BUCKET/ --delete --cache-control "max-age=0" --include "*.html" --include "*.json" --exclude "outputs.json"
          else
            echo "❌ Frontend build output not found"
            echo "📁 Available files:"
            ls -la
            exit 1
          fi

          echo "✅ Frontend deployment completed"

      - name: Invalidate CloudFront Cache
        run: |
          # Extract CloudFront distribution ID from AWS
          DISTRIBUTION_ID=$(aws cloudfront list-distributions --query "DistributionList.Items[?contains(Aliases.Items || [''], '${{ needs.detect-environment.outputs.domain_name }}')].Id" --output text)

          if [ ! -z "$DISTRIBUTION_ID" ]; then
            echo "🔄 Invalidating CloudFront cache for distribution: $DISTRIBUTION_ID"
            aws cloudfront create-invalidation --distribution-id $DISTRIBUTION_ID --paths "/*"
          else
            echo "⚠️ CloudFront distribution not found for domain: ${{ needs.detect-environment.outputs.domain_name }}"
          fi

  # ===========================================
  # Health Checks & Verification
  # ===========================================
  verify-deployment:
    name: Verify Deployment
    runs-on: ubuntu-latest
    needs: [detect-environment, deploy-backend, deploy-frontend]
    if: ${{ needs.detect-environment.outputs.should_deploy == 'true' || github.event_name == 'workflow_dispatch' }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download Terraform outputs
        uses: actions/download-artifact@v4
        with:
          name: terraform-outputs-${{ needs.detect-environment.outputs.environment }}

      - name: Health Check Internal AWS API (Critical)
        run: |
          echo "🔧 Step 1: Testing Internal AWS API (CRITICAL - must pass)"

          # Get internal API Gateway URL from Terraform outputs
          if [ -f outputs.json ]; then
            INTERNAL_API_URL=$(cat outputs.json | jq -r '.api_url.value // empty')
          fi

          if [ -z "$INTERNAL_API_URL" ]; then
            echo "❌ Could not get internal API URL from Terraform outputs"
            echo "📋 Available outputs:"
            cat outputs.json | jq .
            exit 1
          fi

          echo "🎯 Internal API URL: $INTERNAL_API_URL"
          echo "🏥 Testing internal health endpoint: $INTERNAL_API_URL/health"

          # Test internal API - MUST pass (5 attempts)
          SUCCESS=false
          for i in {1..5}; do
            echo "🔄 Internal API test attempt $i/5..."
            if curl -f "$INTERNAL_API_URL/health" -m 15 -s -o response.json; then
              echo "✅ Internal API health check PASSED"
              echo "📋 Response:"
              cat response.json | jq . 2>/dev/null || cat response.json
              SUCCESS=true
              break
            else
              echo "❌ Internal API test attempt $i/5 failed"
              if [ $i -lt 5 ]; then
                echo "⏳ Waiting 20 seconds before retry..."
                sleep 20
              fi
            fi
          done

          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "🚨 CRITICAL: Internal AWS API failed all 5 attempts"
            echo "🚨 This indicates infrastructure deployment issues"
            echo "🚨 Failing the workflow..."
            exit 1
          fi

          echo "✅ Internal AWS API verification completed successfully"

      - name: Health Check Public Domain API (Warning Only)
        continue-on-error: true
        run: |
          echo ""
          echo "🌐 Step 2: Testing Public Domain API (warning only if fails)"

          PUBLIC_API_URL="${{ needs.detect-environment.outputs.api_url }}"
          echo "🎯 Public API URL: $PUBLIC_API_URL"
          echo "🏥 Testing public health endpoint: $PUBLIC_API_URL/health"

          # Test public API - warn only (3 attempts)
          SUCCESS=false
          for i in {1..3}; do
            echo "🔄 Public API test attempt $i/3..."
            if curl -f "$PUBLIC_API_URL/health" -m 15 -s -o public_response.json; then
              echo "✅ Public API health check PASSED"
              echo "📋 Response:"
              cat public_response.json | jq . 2>/dev/null || cat public_response.json
              SUCCESS=true
              break
            else
              echo "⚠️ Public API test attempt $i/3 failed"
              if [ $i -lt 3 ]; then
                echo "⏳ Waiting 30 seconds before retry (DNS propagation)..."
                sleep 30
              fi
            fi
          done

          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "⚠️ WARNING: Public domain API failed all 3 attempts"
            echo "⚠️ This is often due to DNS propagation delays"
            echo "⚠️ Internal API is working, so deployment is successful"
            echo "⚠️ Public domain should work within 24 hours"
            
            # Set output for summary
            echo "PUBLIC_API_STATUS=FAILED" >> $GITHUB_ENV
          else
            echo "PUBLIC_API_STATUS=PASSED" >> $GITHUB_ENV
          fi

      - name: Health Check Internal S3 Website (Critical)
        run: |
          echo ""
          echo "🌐 Step 3a: Testing Internal S3 Website (CRITICAL - must pass)"

          # Get internal S3 website URL from Terraform outputs
          if [ -f outputs.json ]; then
            INTERNAL_WEBSITE_URL=$(cat outputs.json | jq -r '.website_url.value // empty')
            S3_BUCKET=$(cat outputs.json | jq -r '.website_bucket_name.value // empty')
          fi

          # Fallback to construct S3 website URL if not in outputs
          if [ -z "$INTERNAL_WEBSITE_URL" ] && [ -n "$S3_BUCKET" ]; then
            INTERNAL_WEBSITE_URL="http://${S3_BUCKET}.s3-website-${{ env.AWS_REGION }}.amazonaws.com"
          fi

          if [ -z "$INTERNAL_WEBSITE_URL" ] || [ -z "$S3_BUCKET" ]; then
            echo "❌ Could not get S3 bucket info from Terraform outputs"
            echo "📋 Available outputs:"
            cat outputs.json | jq .
            exit 1
          fi

          echo "🎯 S3 Bucket: $S3_BUCKET"
          echo "🎯 Internal S3 Website URL: $INTERNAL_WEBSITE_URL"

          # Step 1: Check if S3 bucket exists and get info
          echo ""
          echo "🔍 Step 1: Checking S3 bucket existence and configuration..."
          if aws s3api head-bucket --bucket "$S3_BUCKET" 2>/dev/null; then
            echo "✅ S3 bucket exists: $S3_BUCKET"
          else
            echo "❌ S3 bucket does not exist or is not accessible: $S3_BUCKET"
            exit 1
          fi

          # Step 2: Check website configuration
          echo ""
          echo "🔍 Step 2: Checking S3 website configuration..."
          if aws s3api get-bucket-website --bucket "$S3_BUCKET" > website-config.json 2>/dev/null; then
            echo "✅ S3 website configuration enabled"
            echo "📋 Website config:"
            cat website-config.json | jq .
          else
            echo "❌ S3 website configuration not enabled"
            echo "🔧 This bucket is not configured for static website hosting"
            exit 1
          fi

          # Step 3: Check if files were deployed
          echo ""
          echo "🔍 Step 3: Checking deployed files..."
          FILE_COUNT=$(aws s3 ls s3://$S3_BUCKET/ --recursive | wc -l)
          echo "📁 Files in bucket: $FILE_COUNT"

          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "❌ No files found in S3 bucket"
            echo "🚨 Frontend deployment may have failed"
            exit 1
          fi

          # Check for index.html specifically
          if aws s3api head-object --bucket "$S3_BUCKET" --key "index.html" >/dev/null 2>&1; then
            echo "✅ index.html found in bucket"
          else
            echo "❌ index.html not found in bucket"
            echo "📋 Available files:"
            aws s3 ls s3://$S3_BUCKET/ --recursive | head -10
            exit 1
          fi

          # Step 4: Check bucket policy for public read access
          echo ""
          echo "🔍 Step 4: Checking bucket policy..."
          if aws s3api get-bucket-policy --bucket "$S3_BUCKET" > bucket-policy.json 2>/dev/null; then
            echo "✅ Bucket policy exists"
            echo "📋 Policy summary:"
            cat bucket-policy.json | jq '.Policy | fromjson | .Statement[] | {Effect, Principal, Action}' 2>/dev/null || echo "Policy format check failed"
          else
            echo "⚠️ No bucket policy found - checking if bucket is publicly accessible"
          fi

          # Step 5: Test website accessibility with detailed error info
          echo ""
          echo "🔍 Step 5: Testing website accessibility..."
          echo "🌐 Testing internal S3 website endpoint: $INTERNAL_WEBSITE_URL"

          # Test internal S3 website with detailed diagnostics
          SUCCESS=false
          for i in {1..3}; do
            echo "🔄 Internal S3 website test attempt $i/3..."
            
            # Get detailed curl response
            HTTP_CODE=$(curl -s -o response.html -w "%{http_code}" "$INTERNAL_WEBSITE_URL" -m 15)
            
            if [ "$HTTP_CODE" = "200" ]; then
              echo "✅ Internal S3 website health check PASSED (HTTP $HTTP_CODE)"
              echo "📋 Response size: $(wc -c < response.html 2>/dev/null || echo 'unknown') bytes"
              SUCCESS=true
              break
            else
              echo "❌ Internal S3 website test failed (HTTP $HTTP_CODE)"
              
              # Provide specific error guidance
              case "$HTTP_CODE" in
                "403")
                  echo "🚨 HTTP 403: Access denied - bucket policy issue"
                  ;;
                "404") 
                  echo "🚨 HTTP 404: Not found - website configuration or DNS issue"
                  ;;
                "000")
                  echo "🚨 HTTP 000: Connection failed - DNS or network issue"
                  ;;
                *)
                  echo "🚨 HTTP $HTTP_CODE: Unexpected response"
                  ;;
              esac
              
              if [ $i -lt 3 ]; then
                echo "⏳ Waiting 20 seconds before retry..."
                sleep 20
              fi
            fi
          done

          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "🚨 CRITICAL: Internal S3 website failed all diagnostic checks"
            echo "🚨 Last HTTP response code: $HTTP_CODE"
            echo "🚨 This indicates S3 static website deployment or configuration issues"
            
            # Additional debugging info
            echo ""
            echo "🔧 Debugging Information:"
            echo "  Bucket: $S3_BUCKET"
            echo "  Website URL: $INTERNAL_WEBSITE_URL"
            echo "  Files in bucket: $FILE_COUNT"
            echo "  Region: ${{ env.AWS_REGION }}"
            
            echo ""
            echo "🔧 Possible fixes:"
            echo "  1. Check if frontend deployment step succeeded"
            echo "  2. Verify S3 bucket policy allows public read access"
            echo "  3. Confirm S3 website configuration is correct"
            echo "  4. Check if index.html was deployed correctly"
            
            exit 1
          fi

          echo "✅ Internal S3 website verification completed successfully"

      - name: Health Check Public Domain Website (Warning Only)
        continue-on-error: true
        run: |
          echo ""
          echo "🌐 Step 3b: Testing Public Domain Website (warning only if fails)"

          PUBLIC_WEBSITE_URL="https://${{ needs.detect-environment.outputs.domain_name }}"
          echo "🎯 Public Website URL: $PUBLIC_WEBSITE_URL"

          # Test public domain website - warn only (3 attempts)
          SUCCESS=false
          for i in {1..3}; do
            echo "🔄 Public website test attempt $i/3..."
            if curl -f "$PUBLIC_WEBSITE_URL" -m 15 -s -o /dev/null; then
              echo "✅ Public domain website health check PASSED"
              SUCCESS=true
              break
            else
              echo "⚠️ Public website test attempt $i/3 failed"
              if [ $i -lt 3 ]; then
                echo "⏳ Waiting 30 seconds before retry (DNS propagation)..."
                sleep 30
              fi
            fi
          done

          if [ "$SUCCESS" = false ]; then
            echo ""
            echo "⚠️ WARNING: Public domain website failed all 3 attempts"
            echo "⚠️ This is often due to DNS propagation delays"
            echo "⚠️ Internal S3 website is working, so deployment is successful"
            echo "⚠️ Public domain should work within 24 hours"
            echo "WEBSITE_STATUS=FAILED" >> $GITHUB_ENV
          else
            echo "WEBSITE_STATUS=PASSED" >> $GITHUB_ENV
          fi

      - name: Deployment Summary
        run: |
          echo ""
          echo "🎉 Deployment Summary"
          echo "===================="
          echo "Environment: ${{ needs.detect-environment.outputs.environment }}"
          echo ""
          echo "🔧 Infrastructure Status (Critical - All Verified ✅):"
          echo "  Internal API: ✅ PASSED (AWS infrastructure verified)"
          echo "  Internal S3 Website: ✅ PASSED (S3 static hosting verified)"
          echo ""
          echo "🌐 Public Domain Status (DNS-dependent):"
          echo "  Public API: ${PUBLIC_API_STATUS:-UNKNOWN}"
          echo "  Public Website: ${WEBSITE_STATUS:-UNKNOWN}"
          echo ""
          echo "📍 URLs:"
          echo "  Internal API: $(cat outputs.json | jq -r '.api_url.value // "N/A"')"
          echo "  Internal S3 Website: $(cat outputs.json | jq -r '.website_url.value // "N/A"')"
          echo "  Public API: ${{ needs.detect-environment.outputs.api_url }}"
          echo "  Public Website: https://${{ needs.detect-environment.outputs.domain_name }}"
          echo ""
          echo "🔧 Infrastructure Details:"
          echo "  Function: ${{ needs.detect-environment.outputs.function_name }}"
          echo "  S3 Bucket: ${{ needs.detect-environment.outputs.s3_bucket }}"
          echo "  AWS Region: ${{ env.AWS_REGION }}"
          echo ""
          if [ "${PUBLIC_API_STATUS}" = "FAILED" ] || [ "${WEBSITE_STATUS}" = "FAILED" ]; then
            echo "⚠️ DNS PROPAGATION NOTES:"
            if [ "${PUBLIC_API_STATUS}" = "FAILED" ]; then
              echo "  - Public API domain (qa03-api.hibiji.com) may need DNS propagation time"
            fi
            if [ "${WEBSITE_STATUS}" = "FAILED" ]; then
              echo "  - Public website domain (qa03.hibiji.com) may need DNS propagation time"
            fi
            echo "  - DNS propagation can take up to 24 hours globally"
            echo "  - Internal AWS infrastructure is verified and working correctly"
            echo "  - You can test using internal URLs immediately"
            echo "  - Check public URLs again in a few hours"
          else
            echo "🎉 All endpoints verified and working correctly!"
          fi
          echo ""
          echo "✅ Serverless deployment completed successfully!"
          echo "✅ All critical infrastructure components verified working!"
